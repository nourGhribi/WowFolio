{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06RlIxWnThr3"
   },
   "source": [
    "# Deep Learning models\n",
    "## RoBERTa model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was run on a Google cloud Deep Learning VM. We had created a VM with 2vCPUs and 52Go of Memory and an Nvidia Tesla P100 GPU. We recommend as in the other notebooks to run it after installing the requirements `pip install -r requirements.txt` and having a suitable GPU to ensure fast trainng.\n",
    "With the Google Cloud VM it took about 6 hours to fit.\n",
    "We used tensorflow, transformers, and pretrained models from https://huggingface.co/.\n",
    "\n",
    "This model gave us 0.878 in accuracy and 0.878 F1-Score in AiCrowd.\n",
    "And below you'll see an accuracy of 0.8704 on training and 0.8833 on validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZ0eE9VByN7N",
    "outputId": "4d58d176-6890-4f21-8ec4-b3ffa5a44330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Let's import a fast tokenizer that can work on batched inputs\n",
    "# (the 'Fast' tokenizers in HuggingFace)\n",
    "from transformers import RobertaTokenizer, logging as transformers_logging\n",
    "from helpers import create_csv_submission\n",
    "from helpers import load_cleaned_data\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import Convolution1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 17 00:38:07 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   45C    P0    31W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check the current GPU infos\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8151212649712713456\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 3249601242645294926\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2881377164702471986\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15703311680\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5416298941462155982\n",
      "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ommiting repetitions\n",
      "Translating emojis\n",
      "correcting spelling mistakes\n",
      "tokenizing\n",
      "removing stop words\n"
     ]
    }
   ],
   "source": [
    "train_pos,train_neg, test = load_cleaned_data(load=False, full=True,\n",
    "                        emojis=True, repetitions=True,\n",
    "                        numbers=False, hashtag=False,\n",
    "                        apostrophes=False, tokenizing=True,\n",
    "                        slang=False, spelling=True,\n",
    "                        punctuations=False, stop_words=True,\n",
    "                        stemming=False, lemmatizing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "adNas3RSyiZK"
   },
   "outputs": [],
   "source": [
    "x_poss = list(open(\"Project/cleaned_data/cleaned_train_pos_full.txt\", \"r\", encoding='utf-8').readlines())\n",
    "x_poss = [s.strip() for s in x_poss]\n",
    "x_pos = []\n",
    "for elem in x_poss:\n",
    "    if elem!='':\n",
    "        tweet=''\n",
    "        for word in elem.split(','):\n",
    "            tweet+=word+' '\n",
    "        x_pos.append(tweet)\n",
    "x_negg = list(open(\"Project/cleaned_data/cleaned_train_neg_full.txt\", \"r\", encoding='utf-8').readlines())\n",
    "x_negg = [s.strip() for s in x_negg]\n",
    "x_neg = []\n",
    "for elem in x_negg:\n",
    "    if elem!='':\n",
    "        tweet=''\n",
    "        for word in elem.split(','):\n",
    "            tweet+=word+' '\n",
    "        x_neg.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Z8tH4H0cZwLd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a0fc9c953c4463a71c1449f87d9193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=898823.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bb0b68a7b84c8089833e863dba1b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=456318.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transformers_logging.set_verbosity_warning()\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fSwuQfI8lFiD"
   },
   "outputs": [],
   "source": [
    "max_length = 126\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ioV2YKjclFiE"
   },
   "outputs": [],
   "source": [
    "def convert_example_to_feature(tweet):\n",
    "    return tokenizer(tweet, add_special_tokens=True,\n",
    "                                    max_length=None,\n",
    "                                    pad_to_max_length=True,\n",
    "                                    return_attention_mask=True,\n",
    "                                    return_token_type_ids=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kus0hsxlVh1w",
    "outputId": "e7438540-abc9-41cb-c4c8-3613e73268ab"
   },
   "outputs": [],
   "source": [
    "bert_x = convert_example_to_feature((x_pos+x_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "9kU5gvJsY2UO"
   },
   "outputs": [],
   "source": [
    "y = np.concatenate([np.ones(len(x_pos)), np.zeros(len(x_neg))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01oS70cNlFiF",
    "outputId": "61145a6e-881e-432c-e274-bf809084ef39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaForSequenceClassification: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model= TFRobertaForSequenceClassification.from_pretrained(\"roberta-base\")\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE, from_logits=True)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_roberta_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "roberta (TFRobertaMainLayer) multiple                  124645632 \n",
      "_________________________________________________________________\n",
      "classifier (TFRobertaClassif multiple                  592130    \n",
      "=================================================================\n",
      "Total params: 125,237,762\n",
      "Trainable params: 125,237,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pos, x_neg = (0, 0) # optimize memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "YuT-DwrBmXYH"
   },
   "outputs": [],
   "source": [
    "attention_mask = np.array(bert_x['attention_mask'],dtype=np.int8)\n",
    "input_ids= np.array(bert_x['input_ids'],dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_roberta_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "roberta (TFRobertaMainLayer) multiple                  124645632 \n",
      "_________________________________________________________________\n",
      "classifier (TFRobertaClassif multiple                  592130    \n",
      "=================================================================\n",
      "Total params: 125,237,762\n",
      "Trainable params: 125,237,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "UYTBBsMTeGDu"
   },
   "outputs": [],
   "source": [
    "bert_x = 0 # to optimize memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "L-Yy5HgA0Xuk"
   },
   "outputs": [],
   "source": [
    "indices = np.random.permutation(input_ids.shape[0])\n",
    "training_idx, test_idx = indices[:2000000], indices[2000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "COgJ-F-plFiF"
   },
   "outputs": [],
   "source": [
    "train_input_ids = tf.convert_to_tensor(input_ids[training_idx,:])\n",
    "train_att_mask = tf.convert_to_tensor(attention_mask[training_idx,:])\n",
    "y_train = tf.convert_to_tensor(y[training_idx],dtype=tf.float32)\n",
    "\n",
    "\n",
    "test_input_ids = tf.convert_to_tensor(input_ids[test_idx,:])\n",
    "test_att_mask = tf.convert_to_tensor(attention_mask[test_idx,:])\n",
    "y_test = tf.convert_to_tensor(y[test_idx],dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "ptvWmnoqtxKx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification_1/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification_1/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification_1/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification_1/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification_1/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification_1/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification_1/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification_1/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "31250/31250 [==============================] - 30729s 983ms/step - loss: 0.2976 - accuracy: 0.8704 - val_loss: 0.2759 - val_accuracy: 0.8833\n"
     ]
    }
   ],
   "source": [
    "bert_history = model.fit([train_input_ids,train_att_mask], \n",
    "      y_train,\n",
    "      validation_data=([test_input_ids,test_att_mask], y_test),\n",
    "      epochs=1, batch_size=batch_size, verbose=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./full_training_roberta_weights_1M.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "gdqeJZ1Dy9Q8"
   },
   "outputs": [],
   "source": [
    "tesst = list(open(\"Project/cleaned_data/cleaned_test_data.txt\", \"r\", encoding='utf-8').readlines())\n",
    "tesst = [s.strip() for s in tesst]\n",
    "test = []\n",
    "for elem in tesst:\n",
    "    if elem!='':\n",
    "        tweet=''\n",
    "        for word in elem.split(','):\n",
    "            tweet+=word+' '\n",
    "        test.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfC1LJZz-d1E",
    "outputId": "875e3401-a98f-44ba-d534-fd8ca8d7c6d0"
   },
   "outputs": [],
   "source": [
    "bert_test = convert_example_to_feature(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "vJ10xGWHlFiG"
   },
   "outputs": [],
   "source": [
    "input_ids = tf.convert_to_tensor(bert_test.get('input_ids'))\n",
    "attention_mask =tf.convert_to_tensor(bert_test.get('attention_mask'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "hZamICYClFiG"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict([input_ids,attention_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "ArcL8z3clFiH"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x)/sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "BlfSmj6ulFiI"
   },
   "outputs": [],
   "source": [
    "predictions = [softmax(x) for x in y_pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "4yC3JoFylFiI"
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "for elem in predictions:\n",
    "    if elem[0]>elem[1] : x=-1\n",
    "    else : x = 1\n",
    "    output.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "tvanyM7BlFiI"
   },
   "outputs": [],
   "source": [
    "create_csv_submission(output, './roBERTa_FULL.csv') "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
