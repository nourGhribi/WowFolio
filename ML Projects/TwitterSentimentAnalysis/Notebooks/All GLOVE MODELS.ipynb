{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"All GLOVE MODELS.ipynb","provenance":[],"collapsed_sections":["8Q4-rDsYChGE","UdvrRXv7ChGG","-PSoFopuChGH","KZwA-6kjChGJ","dWD1IN7xChGK","zOz5SyCZChGL","JGwwdoMAChGL","5xYGWbjbChGN","qF7J7FshChGO","FHvBKBAxChGR","hnpVwo9vChGR"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"V7lcXpTqChF1"},"source":["# Pretrained GLOVE"]},{"cell_type":"markdown","metadata":{"id":"FrhwIA-2ChF9"},"source":["##  Load data"]},{"cell_type":"code","metadata":{"id":"K3YTmTeqChF-"},"source":["x_poss = list(open(\"twitter-datasets/cleaned_data/cleaned_train_pos.txt\", \"r\", encoding='utf-8').readlines())\n","x_poss = [s.strip() for s in x_poss]\n","x_pos = []\n","for elem in x_poss:\n","    if elem!='':\n","        tweet=''\n","        for word in elem.split(','):\n","            tweet+=word+' '\n","        x_pos.append(tweet)\n","x_negg = list(open(\"twitter-datasets/cleaned_data/cleaned_train_neg.txt\", \"r\", encoding='utf-8').readlines())\n","x_negg = [s.strip() for s in x_negg]\n","x_neg = []\n","for elem in x_negg:\n","    if elem!='':\n","        tweet=''\n","        for word in elem.split(','):\n","            tweet+=word+' '\n","        x_neg.append(tweet)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c8hAA7ZGChF_"},"source":["tesst = list(open(\"twitter-datasets/cleaned_data/cleaned_test_data.txt\", \"r\", encoding='utf-8').readlines())\n","tesst = [s.strip() for s in tesst]\n","test = []\n","for elem in tesst:\n","    if elem!='':\n","        tweet=''\n","        for word in elem.split(','):\n","            tweet+=word+' '\n","        test.append(tweet)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IMQ4RswKChF_"},"source":["import tensorflow as tf\n","from keras.models import Sequential\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import GlobalAveragePooling1D\n","from keras.layers import Convolution1D\n","from keras.layers import MaxPooling1D\n","from keras.layers import Embedding\n","from keras.layers import LSTM\n","from keras.preprocessing import sequence\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oUP0aPIzChGA"},"source":["X = x_pos + x_neg\n","y = np.ones(len(x_pos)) + np.zeros(len(x_neg))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s-26tQ38ChGA"},"source":["maxs = []\n","for elem in X:\n","    maxs.append(len(elem.split(\" \")))\n","max_ = max(maxs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B4lUWZUxChGA"},"source":["MAX_LENGTH = 30\n","#MAX_LENGTH = max_\n","#MAX_LENGTH = 80"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7IiLKuUKChGB"},"source":["def load_glove_embeddings(file):\n","    '''\n","    This method returns a dict with the word followed by it's vector\n","    '''\n","    word_embedding = {}\n","    f = open(file,'rb')\n","    for line in f:\n","        values = line.split()\n","        word_embedding[values[0]] = np.array([float(x) for x in values[1:]])\n","    f.close()\n","    return word_embedding"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YoHJVT5hChGB"},"source":["word_embedding = load_glove_embeddings(\"glove.6B/glove.6B.200d.txt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HpnZMO6tChGC"},"source":["tokenizer = Tokenizer(filters='')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eBcr-4CiChGC","outputId":"7799e30f-71e4-475f-92f6-47e121271bc2"},"source":["def create_sequences(max_, X, X_test):\n","    # fit train words to tokenizer\n","    tokenizer.fit_on_texts(X)\n","    # get words and their indexes\n","    word_index = tokenizer.word_index\n","    # number of words\n","    nb_word = len(word_index)\n","    print(nb_word)\n","    # transform text to sequence\n","    X_sequences = tokenizer.texts_to_sequences(X)\n","    test_sequences = tokenizer.texts_to_sequences(X_test)\n","    \n","    # Pad sequences\n","    X_sequences = sequence.pad_sequences(X_sequences, maxlen=MAX_LENGTH,padding='pre')\n","    test_sequences = sequence.pad_sequences(test_sequences, maxlen=MAX_LENGTH,padding='pre')\n","\n","    # create y, first pos then neg\n","    train_size = len(X)\n","    y = np.array(int(train_size/2) * [1] + int(train_size/2) * [0])\n","\n","    # create indices \n","    indices = np.arange(X_sequences.shape[0])\n","    np.random.shuffle(indices)\n","    X_sequences = X_sequences[indices]\n","    y = y[indices]\n","    print(\"Sequences created!\") \n","    return X_sequences, test_sequences, y, nb_word, word_index\n","\n","\n","X_sequences, test_sequences, y, nb_word, word_index = create_sequences(max_, X, test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["65015\n","Sequences created!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z4YJ_dZTChGE"},"source":["def create_glove_matrix(word_embedding, X, nb_word):\n","    '''\n","    This method creates an embedding matrix from a dict passed in argument\n","    '''\n","    X_splitted = [x.split() for x in X]\n","\n","    glove_matrix = np.zeros((nb_word + 1, 200))\n","    for word, i in word_index.items():\n","        embedding_vector = word_embedding.get(word.encode())\n","        if embedding_vector is not None:\n","            # words not found in embedding index will be all-zeros.\n","            glove_matrix[i] = embedding_vector\n","    print('Matrix created')\n","    \n","    return glove_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AKAYT-OVChGE","outputId":"ee351ec6-32c7-4798-eb33-c7d7bd89d15b"},"source":["glove_matrix = create_glove_matrix(word_embedding, X,nb_word)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Matrix created\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8Q4-rDsYChGE"},"source":["### Bidirectional LSTM(30), Activation RELU"]},{"cell_type":"code","metadata":{"id":"hjkaysg1ChGF","outputId":"873af571-c61d-401f-99f0-1c110275cf18"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, Bidirectional, Flatten\n","from tensorflow.python.keras.layers import LSTM, CuDNNLSTM\n","from keras.callbacks import EarlyStopping\n","import pyopencl as cl\n","\n","\n","callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n","\n","model = Sequential()\n","model.add(Embedding(nb_word+1, 200, input_length=X_sequences.shape[1], weights=[glove_matrix]))\n","model.add(Bidirectional(LSTM(30)))\n","model.add(Flatten())\n","model.add(Dense(1, activation='relu'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 30, 200)           13003200  \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 60)                55440     \n","_________________________________________________________________\n","flatten (Flatten)            (None, 60)                0         \n","_________________________________________________________________\n","dense (Dense)                (None, 1)                 61        \n","=================================================================\n","Total params: 13,058,701\n","Trainable params: 13,058,701\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nkdmdGv9ChGF","outputId":"9f502699-61dc-4fcf-94cb-9f93d26f37ec"},"source":["model.fit(X_sequences, y, validation_split=0.1, epochs=10, batch_size=128, verbose=1, shuffle=True,callbacks=[callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","1407/1407 [==============================] - 379s 269ms/step - loss: 0.5039 - accuracy: 0.7610 - val_loss: 0.4705 - val_accuracy: 0.7834\n","Epoch 2/10\n","1407/1407 [==============================] - 376s 267ms/step - loss: 0.4221 - accuracy: 0.8138 - val_loss: 0.4404 - val_accuracy: 0.8030\n","Epoch 3/10\n","1407/1407 [==============================] - 373s 265ms/step - loss: 0.3804 - accuracy: 0.8382 - val_loss: 0.6921 - val_accuracy: 0.7200\n","Epoch 4/10\n","1407/1407 [==============================] - 379s 269ms/step - loss: 0.3814 - accuracy: 0.8379 - val_loss: 0.4710 - val_accuracy: 0.7839\n","Epoch 5/10\n","1407/1407 [==============================] - 360s 256ms/step - loss: 0.3633 - accuracy: 0.8508 - val_loss: 0.5000 - val_accuracy: 0.8055\n","Epoch 6/10\n","1407/1407 [==============================] - 363s 258ms/step - loss: 0.3286 - accuracy: 0.8619 - val_loss: 0.5681 - val_accuracy: 0.8063\n","Epoch 7/10\n","1407/1407 [==============================] - 379s 270ms/step - loss: 0.2984 - accuracy: 0.8757 - val_loss: 0.6284 - val_accuracy: 0.8049\n","Epoch 8/10\n","1407/1407 [==============================] - 379s 270ms/step - loss: 0.2835 - accuracy: 0.8820 - val_loss: 0.6508 - val_accuracy: 0.8023\n","Epoch 9/10\n","1407/1407 [==============================] - 383s 272ms/step - loss: 0.2920 - accuracy: 0.8809 - val_loss: 0.6767 - val_accuracy: 0.7908\n","Epoch 10/10\n","1407/1407 [==============================] - 370s 263ms/step - loss: 0.2913 - accuracy: 0.8822 - val_loss: 0.6266 - val_accuracy: 0.7952\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x2245af0c648>"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"UdvrRXv7ChGG"},"source":["### LSTM(30), Activation RELU"]},{"cell_type":"code","metadata":{"id":"YDorF92lChGG","outputId":"af5e13b9-57f3-4426-fce9-e760b57ae455"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, Bidirectional, Flatten\n","from tensorflow.python.keras.layers import LSTM, CuDNNLSTM\n","from keras.callbacks import EarlyStopping\n","import pyopencl as cl\n","\n","\n","callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n","\n","model = Sequential()\n","model.add(Embedding(nb_word+1, 200, input_length=X_sequences.shape[1], weights=[glove_matrix]))\n","model.add(LSTM(30))\n","model.add(Flatten())\n","model.add(Dense(1, activation='relu'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, 30, 200)           13003200  \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 30)                27720     \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 30)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 31        \n","=================================================================\n","Total params: 13,030,951\n","Trainable params: 13,030,951\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mubcHh1-ChGH","outputId":"610a2054-e6a9-4053-86b3-c3f7b14511a7"},"source":["model.fit(X_sequences, y, validation_split=0.1, epochs=4, batch_size=128, verbose=1, shuffle=True,callbacks=[callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/4\n","1407/1407 [==============================] - 332s 236ms/step - loss: 0.5153 - accuracy: 0.7412 - val_loss: 0.4571 - val_accuracy: 0.7921\n","Epoch 2/4\n","1407/1407 [==============================] - 313s 222ms/step - loss: 0.4479 - accuracy: 0.7900 - val_loss: 0.4476 - val_accuracy: 0.8019\n","Epoch 3/4\n","1407/1407 [==============================] - 357s 254ms/step - loss: 0.4087 - accuracy: 0.8199 - val_loss: 0.4685 - val_accuracy: 0.7854\n","Epoch 4/4\n","1407/1407 [==============================] - 354s 251ms/step - loss: 0.4137 - accuracy: 0.8141 - val_loss: 0.4665 - val_accuracy: 0.7950\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x224065dc188>"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"-PSoFopuChGH"},"source":["### Bidirectional LSTM(30), Activation sigmoid"]},{"cell_type":"code","metadata":{"id":"Xfg2aBOAChGH","outputId":"26018c83-eefb-4134-c8fb-fdd8339fa2b5"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, Bidirectional, Flatten\n","from tensorflow.python.keras.layers import LSTM, CuDNNLSTM\n","from keras.callbacks import EarlyStopping\n","import pyopencl as cl\n","\n","\n","callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n","\n","model = Sequential()\n","model.add(Embedding(nb_word+1, 200, input_length=X_sequences.shape[1], weights=[glove_matrix]))\n","model.add(Bidirectional(LSTM(30)))\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, 30, 200)           13003200  \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 60)                55440     \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 60)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 61        \n","=================================================================\n","Total params: 13,058,701\n","Trainable params: 13,058,701\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RKGjkiNkVB5_","executionInfo":{"status":"ok","timestamp":1608171128698,"user_tz":-60,"elapsed":1974952,"user":{"displayName":"Ahmed Ben Haj Yahia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqSq89M7CrOFJIdKpCPimBOKXHPTj5flicSusF=s64","userId":"06538742934651146425"}},"outputId":"2debb760-5b70-4b73-e0e8-94d85da6760d"},"source":["model.fit(X_sequences, y, validation_split=0.1, epochs=4, batch_size=128, verbose=1, shuffle=True,callbacks=[callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/4\n","1407/1407 [==============================] - 508s 361ms/step - loss: 0.4298 - accuracy: 0.7896 - val_loss: 0.3921 - val_accuracy: 0.8152\n","Epoch 2/4\n","1407/1407 [==============================] - 499s 354ms/step - loss: 0.3553 - accuracy: 0.8372 - val_loss: 0.3910 - val_accuracy: 0.8148\n","Epoch 3/4\n","1407/1407 [==============================] - 481s 342ms/step - loss: 0.3061 - accuracy: 0.8627 - val_loss: 0.4098 - val_accuracy: 0.8154\n","Epoch 4/4\n","1407/1407 [==============================] - 479s 340ms/step - loss: 0.2649 - accuracy: 0.8841 - val_loss: 0.4408 - val_accuracy: 0.8091\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fd680ffa7b8>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"KZwA-6kjChGJ"},"source":["### LSTM(30), Activation sigmoid"]},{"cell_type":"code","metadata":{"id":"HFb3jDwxChGJ","outputId":"17c8695b-9e4b-4ae7-f26f-4a84cbd30053"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, Bidirectional, Flatten\n","from tensorflow.python.keras.layers import LSTM, CuDNNLSTM\n","from keras.callbacks import EarlyStopping\n","import pyopencl as cl\n","\n","\n","callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n","\n","model = Sequential()\n","model.add(Embedding(nb_word+1, 200, input_length=X_sequences.shape[1], weights=[glove_matrix]))\n","model.add(LSTM(30))\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_4 (Embedding)      (None, 30, 200)           13003200  \n","_________________________________________________________________\n","lstm_3 (LSTM)                (None, 30)                27720     \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 30)                0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 31        \n","=================================================================\n","Total params: 13,030,951\n","Trainable params: 13,030,951\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"60gFLganChGJ","outputId":"1927975f-10e9-4a4e-80d0-1b2fad0e8b9e"},"source":["model.fit(X_sequences, y, validation_split=0.1, epochs=4, batch_size=128, verbose=1, shuffle=True,callbacks=[callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/4\n","1407/1407 [==============================] - 340s 241ms/step - loss: 0.4311 - accuracy: 0.7896 - val_loss: 0.3946 - val_accuracy: 0.8121\n","Epoch 2/4\n","1407/1407 [==============================] - 336s 239ms/step - loss: 0.3539 - accuracy: 0.8367 - val_loss: 0.3928 - val_accuracy: 0.8163\n","Epoch 3/4\n","1407/1407 [==============================] - 365s 260ms/step - loss: 0.3060 - accuracy: 0.8628 - val_loss: 0.4156 - val_accuracy: 0.8110\n","Epoch 4/4\n","1407/1407 [==============================] - 363s 258ms/step - loss: 0.2672 - accuracy: 0.8820 - val_loss: 0.4399 - val_accuracy: 0.8081\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x224080de588>"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"dWD1IN7xChGK"},"source":["### Glove + GRU(30) + Activation Sigmoid"]},{"cell_type":"code","metadata":{"id":"jfQ5EyEzChGK","outputId":"57a216a5-6e05-4d1b-e48d-77dc46badd20"},"source":["from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Conv1D\n","from keras.layers import Bidirectional, GlobalMaxPool1D\n","from keras.models import Model\n","from keras import initializers, regularizers, constraints, optimizers, layers\n","\n","np.random.seed(12)\n","\n","model = Sequential()\n","model.add(Embedding(nb_word+1, 200, input_length=X_sequences.shape[1], weights=[glove_matrix]))\n","model.add(GRU(100, dropout=0.2))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n","\n","model.fit(X_sequences, y, validation_split=0.1, epochs=2, batch_size=128, verbose=1, shuffle=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_6 (Embedding)      (None, 30, 200)           13003200  \n","_________________________________________________________________\n","gru (GRU)                    (None, 100)               90600     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 101       \n","=================================================================\n","Total params: 13,093,901\n","Trainable params: 13,093,901\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/2\n","1407/1407 [==============================] - 374s 266ms/step - loss: 0.4334 - accuracy: 0.7860 - val_loss: 0.3895 - val_accuracy: 0.8163\n","Epoch 2/2\n","1407/1407 [==============================] - 374s 266ms/step - loss: 0.3636 - accuracy: 0.8312 - val_loss: 0.3867 - val_accuracy: 0.8191\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x2245b7f5208>"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"zOz5SyCZChGL"},"source":["### Glove + bidirectional GRU(30) + Activation Sigmoid"]},{"cell_type":"code","metadata":{"id":"Oz_jdtL1ChGL","outputId":"92e7d529-15d9-4e0a-be48-a54362576189"},"source":["from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Conv1D\n","from keras.layers import Bidirectional, GlobalMaxPool1D\n","from keras.models import Model\n","from keras import initializers, regularizers, constraints, optimizers, layers\n","\n","np.random.seed(12)\n","\n","model = Sequential()\n","model.add(Embedding(nb_word+1, 200, input_length=X_sequences.shape[1], weights=[glove_matrix]))\n","model.add(Bidirectional(GRU(100, dropout=0.2)))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n","\n","model.fit(X_sequences, y, validation_split=0.1, epochs=2, batch_size=128, verbose=1, shuffle=True)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_7 (Embedding)      (None, 30, 200)           13003200  \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 200)               181200    \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1)                 201       \n","=================================================================\n","Total params: 13,184,601\n","Trainable params: 13,184,601\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/2\n","1407/1407 [==============================] - 435s 309ms/step - loss: 0.4345 - accuracy: 0.7871 - val_loss: 0.3901 - val_accuracy: 0.8146\n","Epoch 2/2\n","1407/1407 [==============================] - 491s 349ms/step - loss: 0.3643 - accuracy: 0.8310 - val_loss: 0.3859 - val_accuracy: 0.8210\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x2245d13c2c8>"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"JGwwdoMAChGL"},"source":["### Glove + GRU(30) + Activation Relu"]},{"cell_type":"code","metadata":{"id":"6GxZkr97ChGM","outputId":"4c66d6ca-186e-406e-d111-db88eb7571a8"},"source":["from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Conv1D\n","from keras.layers import Bidirectional, GlobalMaxPool1D\n","from keras.models import Model\n","from keras import initializers, regularizers, constraints, optimizers, layers\n","\n","np.random.seed(12)\n","\n","model = Sequential()\n","model.add(Embedding(nb_word+1, 200, input_length=X_sequences.shape[1], weights=[glove_matrix]))\n","model.add(GRU(100, dropout=0.2))\n","model.add(Dense(1, activation='relu'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_8 (Embedding)      (None, 30, 200)           13003200  \n","_________________________________________________________________\n","gru_2 (GRU)                  (None, 100)               90600     \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 1)                 101       \n","=================================================================\n","Total params: 13,093,901\n","Trainable params: 13,093,901\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"81WvFGMZChGM","outputId":"f1e16931-76ce-4697-e076-17e3b6f7fcb2"},"source":["model.fit(X_sequences, y, validation_split=0.1, epochs=5, batch_size=128, verbose=1, shuffle=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","1407/1407 [==============================] - 434s 308ms/step - loss: 3.5997 - accuracy: 0.5967 - val_loss: 3.5394 - val_accuracy: 0.5789\n","Epoch 2/5\n","1407/1407 [==============================] - 373s 265ms/step - loss: 3.2143 - accuracy: 0.6135 - val_loss: 3.1619 - val_accuracy: 0.6077\n","Epoch 3/5\n","1407/1407 [==============================] - 365s 259ms/step - loss: 3.3820 - accuracy: 0.6213 - val_loss: 3.0970 - val_accuracy: 0.6205\n","Epoch 4/5\n","1407/1407 [==============================] - 383s 272ms/step - loss: 1.9264 - accuracy: 0.7131 - val_loss: 0.5561 - val_accuracy: 0.7773\n","Epoch 5/5\n","1407/1407 [==============================] - 382s 271ms/step - loss: 0.4639 - accuracy: 0.8147 - val_loss: 0.5456 - val_accuracy: 0.7882\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x22403cb1208>"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"5xYGWbjbChGN"},"source":["### Glove + Bidirectional GRU(30) + Activation Relu"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQ2zB59CVB6q","executionInfo":{"status":"ok","timestamp":1608176939196,"user_tz":-60,"elapsed":881,"user":{"displayName":"Ahmed Ben Haj Yahia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqSq89M7CrOFJIdKpCPimBOKXHPTj5flicSusF=s64","userId":"06538742934651146425"}},"outputId":"c183a6d1-0a0a-4e36-8ff8-cff8afd6e2b0"},"source":["from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Conv1D\n","from keras.layers import Bidirectional, GlobalMaxPool1D\n","from keras.models import Model\n","from keras import initializers, regularizers, constraints, optimizers, layers\n","\n","np.random.seed(12)\n","\n","model = Sequential()\n","model.add(Embedding(nb_word+1, 200, input_length=X_sequences.shape[1], weights=[glove_matrix]))\n","model.add(GRU(100, dropout=0.2))\n","model.add(Dense(1, activation='relu'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_10\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_10 (Embedding)     (None, 30, 200)           13003200  \n","_________________________________________________________________\n","gru_2 (GRU)                  (None, 100)               90600     \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 1)                 101       \n","=================================================================\n","Total params: 13,093,901\n","Trainable params: 13,093,901\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPowlNnRVB6r","executionInfo":{"status":"ok","timestamp":1608177658056,"user_tz":-60,"elapsed":716861,"user":{"displayName":"Ahmed Ben Haj Yahia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqSq89M7CrOFJIdKpCPimBOKXHPTj5flicSusF=s64","userId":"06538742934651146425"}},"outputId":"70288ff2-f069-4c53-d12c-cd48d3b41a12"},"source":["model.fit(X_sequences, y, validation_split=0.1, epochs=4, batch_size=128, verbose=1, shuffle=True,callbacks=[callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/4\n","1407/1407 [==============================] - 178s 126ms/step - loss: 0.7921 - accuracy: 0.7138 - val_loss: 0.5223 - val_accuracy: 0.7768\n","Epoch 2/4\n","1407/1407 [==============================] - 176s 125ms/step - loss: 0.4560 - accuracy: 0.7974 - val_loss: 0.4439 - val_accuracy: 0.8025\n","Epoch 3/4\n","1407/1407 [==============================] - 177s 126ms/step - loss: 0.6082 - accuracy: 0.7769 - val_loss: 0.4596 - val_accuracy: 0.7890\n","Epoch 4/4\n","1407/1407 [==============================] - 177s 126ms/step - loss: 0.4212 - accuracy: 0.8182 - val_loss: 0.4707 - val_accuracy: 0.7825\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fd5e8583c18>"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"qF7J7FshChGO"},"source":["### Glove + Conv1D + MaxPool1D + Flatten"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PT9bpbdxVB6s","executionInfo":{"status":"ok","timestamp":1608175175740,"user_tz":-60,"elapsed":690,"user":{"displayName":"Ahmed Ben Haj Yahia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqSq89M7CrOFJIdKpCPimBOKXHPTj5flicSusF=s64","userId":"06538742934651146425"}},"outputId":"31e89038-3027-4f6b-ff6b-293bb79a5a95"},"source":["from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Conv1D\n","from keras.layers import Bidirectional, GlobalMaxPool1D\n","from keras.models import Model\n","from keras import initializers, regularizers, constraints, optimizers, layers\n","\n","model = Sequential()\n","model.add(Embedding(nb_word+1, 200, input_length=X_sequences.shape[1], weights=[glove_matrix]))\n","model.add(Convolution1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Flatten())\n","model.add(Dense(250, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_9 (Embedding)      (None, 30, 200)           13003200  \n","_________________________________________________________________\n","conv1d_5 (Conv1D)            (None, 30, 32)            19232     \n","_________________________________________________________________\n","max_pooling1d_4 (MaxPooling1 (None, 15, 32)            0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 480)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 250)               120250    \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 1)                 251       \n","=================================================================\n","Total params: 13,142,933\n","Trainable params: 13,142,933\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z-jgRFrkVB6t","executionInfo":{"status":"ok","timestamp":1608175884197,"user_tz":-60,"elapsed":704289,"user":{"displayName":"Ahmed Ben Haj Yahia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqSq89M7CrOFJIdKpCPimBOKXHPTj5flicSusF=s64","userId":"06538742934651146425"}},"outputId":"bf3c83ad-79d7-4488-f6b9-ed7fd51a80a8"},"source":["model.fit(X_sequences, y, validation_split=0.1, epochs=4, batch_size=128, verbose=1, shuffle=True,callbacks=[callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/4\n","1407/1407 [==============================] - 177s 126ms/step - loss: 0.4340 - accuracy: 0.7852 - val_loss: 0.4017 - val_accuracy: 0.8099\n","Epoch 2/4\n","1407/1407 [==============================] - 173s 123ms/step - loss: 0.3510 - accuracy: 0.8384 - val_loss: 0.3976 - val_accuracy: 0.8154\n","Epoch 3/4\n","1407/1407 [==============================] - 175s 124ms/step - loss: 0.2899 - accuracy: 0.8712 - val_loss: 0.4306 - val_accuracy: 0.8087\n","Epoch 4/4\n","1407/1407 [==============================] - 178s 126ms/step - loss: 0.2319 - accuracy: 0.8987 - val_loss: 0.4799 - val_accuracy: 0.8025\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fd61c25ebe0>"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"FHvBKBAxChGR"},"source":["### Glove + Conv1D + MaxPool1D + Bidirectional LSTM"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZxIxYbyoVB6v","executionInfo":{"status":"ok","timestamp":1608174398803,"user_tz":-60,"elapsed":984,"user":{"displayName":"Ahmed Ben Haj Yahia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqSq89M7CrOFJIdKpCPimBOKXHPTj5flicSusF=s64","userId":"06538742934651146425"}},"outputId":"d5c4e483-bff2-45a1-f7e4-892a6845af8c"},"source":["from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Conv1D\n","from keras.layers import Bidirectional, GlobalMaxPool1D\n","from keras.models import Model\n","from keras import initializers, regularizers, constraints, optimizers, layers\n","\n","model = Sequential()\n","model.add(Embedding(nb_word+1, 50, input_length=X_sequences.shape[1]))\n","model.add(Convolution1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Bidirectional(LSTM(30)))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_8 (Embedding)      (None, 30, 50)            3250800   \n","_________________________________________________________________\n","conv1d_4 (Conv1D)            (None, 30, 32)            4832      \n","_________________________________________________________________\n","max_pooling1d_3 (MaxPooling1 (None, 15, 32)            0         \n","_________________________________________________________________\n","bidirectional_3 (Bidirection (None, 60)                15120     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 61        \n","=================================================================\n","Total params: 3,270,813\n","Trainable params: 3,270,813\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zfCI6stuVB6v","executionInfo":{"status":"ok","timestamp":1608174619396,"user_tz":-60,"elapsed":200126,"user":{"displayName":"Ahmed Ben Haj Yahia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqSq89M7CrOFJIdKpCPimBOKXHPTj5flicSusF=s64","userId":"06538742934651146425"}},"outputId":"4bd497c1-f53a-4d62-f59f-bb931ac90256"},"source":["model.fit(X_sequences, y, validation_split=0.1, epochs=4, batch_size=128, verbose=1, shuffle=True,callbacks=[callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/4\n","1407/1407 [==============================] - 51s 36ms/step - loss: 0.4334 - accuracy: 0.7900 - val_loss: 0.4021 - val_accuracy: 0.8082\n","Epoch 2/4\n","1407/1407 [==============================] - 49s 35ms/step - loss: 0.3468 - accuracy: 0.8419 - val_loss: 0.3961 - val_accuracy: 0.8158\n","Epoch 3/4\n","1407/1407 [==============================] - 48s 34ms/step - loss: 0.2757 - accuracy: 0.8798 - val_loss: 0.4252 - val_accuracy: 0.8095\n","Epoch 4/4\n","1407/1407 [==============================] - 48s 34ms/step - loss: 0.2156 - accuracy: 0.9082 - val_loss: 0.4824 - val_accuracy: 0.8093\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fd61cc68f98>"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"hnpVwo9vChGR"},"source":["### Glove + Conv1D + MaxPool1D + Bidirectional GRU"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"erg48J_2VB6x","executionInfo":{"status":"ok","timestamp":1608173006142,"user_tz":-60,"elapsed":974,"user":{"displayName":"Ahmed Ben Haj Yahia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqSq89M7CrOFJIdKpCPimBOKXHPTj5flicSusF=s64","userId":"06538742934651146425"}},"outputId":"296acf9a-d6c2-47f4-eb00-9ffc2931642a"},"source":["from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Conv1D\n","from keras.layers import Bidirectional, GlobalMaxPool1D\n","from keras.models import Model\n","from keras import initializers, regularizers, constraints, optimizers, layers\n","\n","model = Sequential()\n","model.add(Embedding(nb_word+1, 50, input_length=X_sequences.shape[1]))\n","model.add(Convolution1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Bidirectional(GRU(30)))\n","model.add(Dense\n","(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_7 (Embedding)      (None, 30, 50)            3250800   \n","_________________________________________________________________\n","conv1d_3 (Conv1D)            (None, 30, 32)            4832      \n","_________________________________________________________________\n","max_pooling1d_2 (MaxPooling1 (None, 15, 32)            0         \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 60)                11520     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 61        \n","=================================================================\n","Total params: 3,267,213\n","Trainable params: 3,267,213\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lsuNmuvGVB6x","executionInfo":{"status":"ok","timestamp":1608173215056,"user_tz":-60,"elapsed":201691,"user":{"displayName":"Ahmed Ben Haj Yahia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqSq89M7CrOFJIdKpCPimBOKXHPTj5flicSusF=s64","userId":"06538742934651146425"}},"outputId":"1a4c95be-b0e9-44fc-b7e3-144f8baba038"},"source":["model.fit(X_sequences, y, validation_split=0.1, epochs=4, batch_size=128, verbose=1, shuffle=True,callbacks=[callback])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/4\n","1407/1407 [==============================] - 50s 35ms/step - loss: 0.4329 - accuracy: 0.7902 - val_loss: 0.3974 - val_accuracy: 0.8117\n","Epoch 2/4\n","1407/1407 [==============================] - 49s 35ms/step - loss: 0.3474 - accuracy: 0.8428 - val_loss: 0.3998 - val_accuracy: 0.8114\n","Epoch 3/4\n","1407/1407 [==============================] - 47s 34ms/step - loss: 0.2815 - accuracy: 0.8776 - val_loss: 0.4231 - val_accuracy: 0.8105\n","Epoch 4/4\n","1407/1407 [==============================] - 47s 34ms/step - loss: 0.2228 - accuracy: 0.9067 - val_loss: 0.4857 - val_accuracy: 0.8041\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fd6125a3c88>"]},"metadata":{"tags":[]},"execution_count":27}]}]}