{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models\n",
    "This notebook will be mainly about the different linear models we tried to fit during the first steps into the project\n",
    "\n",
    "---\n",
    "## Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the training tweets and the built GloVe word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ayee tell em ' bitches to come through</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; congrats on making it dude  laug...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>&lt;user&gt; yes ! i'd love to show you guys around ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&lt;user&gt; we'll maybe meet there - bianca</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>&lt;user&gt; hello snooki follow me back please ? i ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  sign\n",
       "0             ayee tell em ' bitches to come through   0.0\n",
       "1  <user> <user> congrats on making it dude  laug...   1.0\n",
       "2  <user> yes ! i'd love to show you guys around ...   1.0\n",
       "3             <user> we'll maybe meet there - bianca   0.0\n",
       "4  <user> hello snooki follow me back please ? i ...   0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_train_data = pd.read_csv('../cleaned_data/train_sample_data.csv')\n",
    "sample_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample_cleaned_emedding were created following the readme provided describing the Project 2.\n",
    "Using `pos_train.txt`, `neg_train.txt` , `cooc.py` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(\"../glove_embeddings/cleaned_embeddings/sample/sample_cleaned_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03639066, -0.09216319,  0.25672143, ...,  0.00438598,\n",
       "         0.27709553, -0.28430814],\n",
       "       [-0.11966957, -0.11714977,  0.31616412, ...,  0.03272727,\n",
       "         0.33447519, -0.35110098],\n",
       "       [-0.03528425, -0.17829468,  0.47392969, ..., -0.03130248,\n",
       "         0.47083008, -0.49161173],\n",
       "       ...,\n",
       "       [ 1.90027776,  0.14359226,  1.00816857, ...,  0.78021657,\n",
       "         1.24922489, -0.67362005],\n",
       "       [-1.26125   ,  0.84964021, -0.49005907, ...,  0.30284872,\n",
       "        -0.33666684,  1.03548732],\n",
       "       [ 0.90150669, -0.12418292, -0.3043387 , ...,  0.00195154,\n",
       "        -0.66822134,  0.13490772]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pickle.load(open('../glove_embeddings/cleaned_embeddings/sample/cleaned_vocab.pkl', \"rb\")) #this file was generated by executing vocab.sh\n",
    "word_embedding = {}\n",
    "for key in vocab.keys():\n",
    "    word_embedding[key] = embeddings[vocab.get(key)] # keys in this dict are not encoded \n",
    "word_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_df = pd.DataFrame(word_embedding).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>&lt;user&gt;</td>\n",
       "      <td>-0.036391</td>\n",
       "      <td>-0.092163</td>\n",
       "      <td>0.256721</td>\n",
       "      <td>0.338181</td>\n",
       "      <td>-0.121974</td>\n",
       "      <td>-0.139507</td>\n",
       "      <td>0.184167</td>\n",
       "      <td>-0.251719</td>\n",
       "      <td>-0.576921</td>\n",
       "      <td>-0.121730</td>\n",
       "      <td>0.302756</td>\n",
       "      <td>-0.304551</td>\n",
       "      <td>-0.325759</td>\n",
       "      <td>0.023690</td>\n",
       "      <td>-0.068419</td>\n",
       "      <td>-0.138550</td>\n",
       "      <td>0.070042</td>\n",
       "      <td>0.004386</td>\n",
       "      <td>0.277096</td>\n",
       "      <td>-0.284308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>!</td>\n",
       "      <td>-0.119670</td>\n",
       "      <td>-0.117150</td>\n",
       "      <td>0.316164</td>\n",
       "      <td>0.530550</td>\n",
       "      <td>-0.216047</td>\n",
       "      <td>-0.211853</td>\n",
       "      <td>0.235751</td>\n",
       "      <td>-0.324863</td>\n",
       "      <td>-0.762572</td>\n",
       "      <td>-0.155339</td>\n",
       "      <td>0.429212</td>\n",
       "      <td>-0.426843</td>\n",
       "      <td>-0.436972</td>\n",
       "      <td>0.040640</td>\n",
       "      <td>-0.101456</td>\n",
       "      <td>-0.207414</td>\n",
       "      <td>0.105051</td>\n",
       "      <td>0.032727</td>\n",
       "      <td>0.334475</td>\n",
       "      <td>-0.351101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>i</td>\n",
       "      <td>-0.035284</td>\n",
       "      <td>-0.178295</td>\n",
       "      <td>0.473930</td>\n",
       "      <td>0.673728</td>\n",
       "      <td>-0.274608</td>\n",
       "      <td>-0.290031</td>\n",
       "      <td>0.329904</td>\n",
       "      <td>-0.479382</td>\n",
       "      <td>-0.982926</td>\n",
       "      <td>-0.234918</td>\n",
       "      <td>0.569792</td>\n",
       "      <td>-0.617194</td>\n",
       "      <td>-0.510677</td>\n",
       "      <td>0.015466</td>\n",
       "      <td>-0.134536</td>\n",
       "      <td>-0.312960</td>\n",
       "      <td>0.116450</td>\n",
       "      <td>-0.031302</td>\n",
       "      <td>0.470830</td>\n",
       "      <td>-0.491612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>you</td>\n",
       "      <td>-0.114303</td>\n",
       "      <td>-0.198763</td>\n",
       "      <td>0.535223</td>\n",
       "      <td>0.777906</td>\n",
       "      <td>-0.313000</td>\n",
       "      <td>-0.328890</td>\n",
       "      <td>0.368641</td>\n",
       "      <td>-0.518103</td>\n",
       "      <td>-1.090565</td>\n",
       "      <td>-0.243941</td>\n",
       "      <td>0.629524</td>\n",
       "      <td>-0.637401</td>\n",
       "      <td>-0.568887</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>-0.187725</td>\n",
       "      <td>-0.365074</td>\n",
       "      <td>0.102648</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>0.510087</td>\n",
       "      <td>-0.503674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>-0.063466</td>\n",
       "      <td>-0.205308</td>\n",
       "      <td>0.459918</td>\n",
       "      <td>0.609123</td>\n",
       "      <td>-0.259797</td>\n",
       "      <td>-0.293759</td>\n",
       "      <td>0.313210</td>\n",
       "      <td>-0.486077</td>\n",
       "      <td>-0.981628</td>\n",
       "      <td>-0.196206</td>\n",
       "      <td>0.508799</td>\n",
       "      <td>-0.520103</td>\n",
       "      <td>-0.495331</td>\n",
       "      <td>0.044647</td>\n",
       "      <td>-0.146040</td>\n",
       "      <td>-0.302999</td>\n",
       "      <td>0.117209</td>\n",
       "      <td>-0.036188</td>\n",
       "      <td>0.404599</td>\n",
       "      <td>-0.458328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>#13</td>\n",
       "      <td>0.578525</td>\n",
       "      <td>0.092677</td>\n",
       "      <td>0.907422</td>\n",
       "      <td>-0.691363</td>\n",
       "      <td>0.490038</td>\n",
       "      <td>0.308752</td>\n",
       "      <td>-0.236962</td>\n",
       "      <td>1.382476</td>\n",
       "      <td>-1.155187</td>\n",
       "      <td>-0.330439</td>\n",
       "      <td>-1.882477</td>\n",
       "      <td>0.570032</td>\n",
       "      <td>-0.948262</td>\n",
       "      <td>0.039559</td>\n",
       "      <td>0.739215</td>\n",
       "      <td>-0.962181</td>\n",
       "      <td>-1.530525</td>\n",
       "      <td>0.159301</td>\n",
       "      <td>-1.720396</td>\n",
       "      <td>2.020875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>#12</td>\n",
       "      <td>0.385156</td>\n",
       "      <td>-1.454628</td>\n",
       "      <td>1.161650</td>\n",
       "      <td>0.566216</td>\n",
       "      <td>2.103580</td>\n",
       "      <td>-0.386169</td>\n",
       "      <td>-0.027361</td>\n",
       "      <td>0.281791</td>\n",
       "      <td>-0.034381</td>\n",
       "      <td>-0.670752</td>\n",
       "      <td>0.183772</td>\n",
       "      <td>-1.114815</td>\n",
       "      <td>0.598311</td>\n",
       "      <td>-0.444628</td>\n",
       "      <td>-1.830605</td>\n",
       "      <td>0.519197</td>\n",
       "      <td>-0.322483</td>\n",
       "      <td>1.008614</td>\n",
       "      <td>1.952389</td>\n",
       "      <td>-0.772046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>#100daystogo</td>\n",
       "      <td>-0.284537</td>\n",
       "      <td>0.066596</td>\n",
       "      <td>-0.502016</td>\n",
       "      <td>0.788958</td>\n",
       "      <td>0.115769</td>\n",
       "      <td>0.754378</td>\n",
       "      <td>0.279218</td>\n",
       "      <td>-0.179337</td>\n",
       "      <td>1.600295</td>\n",
       "      <td>0.917597</td>\n",
       "      <td>-1.725892</td>\n",
       "      <td>-0.180869</td>\n",
       "      <td>0.278357</td>\n",
       "      <td>-0.596489</td>\n",
       "      <td>0.018683</td>\n",
       "      <td>1.149776</td>\n",
       "      <td>-0.771335</td>\n",
       "      <td>0.552752</td>\n",
       "      <td>0.024422</td>\n",
       "      <td>0.559456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>#100days</td>\n",
       "      <td>-0.408373</td>\n",
       "      <td>0.219682</td>\n",
       "      <td>0.812769</td>\n",
       "      <td>1.585777</td>\n",
       "      <td>1.134555</td>\n",
       "      <td>-1.355136</td>\n",
       "      <td>0.017074</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.607982</td>\n",
       "      <td>0.539324</td>\n",
       "      <td>-1.133705</td>\n",
       "      <td>-0.923764</td>\n",
       "      <td>0.991551</td>\n",
       "      <td>0.108570</td>\n",
       "      <td>1.192866</td>\n",
       "      <td>-0.172446</td>\n",
       "      <td>0.771834</td>\n",
       "      <td>1.796897</td>\n",
       "      <td>-0.545241</td>\n",
       "      <td>-0.575005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>#100aday</td>\n",
       "      <td>0.822602</td>\n",
       "      <td>-1.871435</td>\n",
       "      <td>0.550452</td>\n",
       "      <td>1.432141</td>\n",
       "      <td>-0.384931</td>\n",
       "      <td>0.670189</td>\n",
       "      <td>0.830787</td>\n",
       "      <td>0.126167</td>\n",
       "      <td>0.080057</td>\n",
       "      <td>0.232088</td>\n",
       "      <td>-0.744568</td>\n",
       "      <td>-0.666176</td>\n",
       "      <td>-0.013387</td>\n",
       "      <td>-0.392850</td>\n",
       "      <td>-0.151480</td>\n",
       "      <td>0.731952</td>\n",
       "      <td>1.196030</td>\n",
       "      <td>-0.953245</td>\n",
       "      <td>1.958946</td>\n",
       "      <td>0.962804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14179 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4         5  \\\n",
       "<user>       -0.036391 -0.092163  0.256721  0.338181 -0.121974 -0.139507   \n",
       "!            -0.119670 -0.117150  0.316164  0.530550 -0.216047 -0.211853   \n",
       "i            -0.035284 -0.178295  0.473930  0.673728 -0.274608 -0.290031   \n",
       "you          -0.114303 -0.198763  0.535223  0.777906 -0.313000 -0.328890   \n",
       ".            -0.063466 -0.205308  0.459918  0.609123 -0.259797 -0.293759   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "#13           0.578525  0.092677  0.907422 -0.691363  0.490038  0.308752   \n",
       "#12           0.385156 -1.454628  1.161650  0.566216  2.103580 -0.386169   \n",
       "#100daystogo -0.284537  0.066596 -0.502016  0.788958  0.115769  0.754378   \n",
       "#100days     -0.408373  0.219682  0.812769  1.585777  1.134555 -1.355136   \n",
       "#100aday      0.822602 -1.871435  0.550452  1.432141 -0.384931  0.670189   \n",
       "\n",
       "                     6         7         8         9        10        11  \\\n",
       "<user>        0.184167 -0.251719 -0.576921 -0.121730  0.302756 -0.304551   \n",
       "!             0.235751 -0.324863 -0.762572 -0.155339  0.429212 -0.426843   \n",
       "i             0.329904 -0.479382 -0.982926 -0.234918  0.569792 -0.617194   \n",
       "you           0.368641 -0.518103 -1.090565 -0.243941  0.629524 -0.637401   \n",
       ".             0.313210 -0.486077 -0.981628 -0.196206  0.508799 -0.520103   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "#13          -0.236962  1.382476 -1.155187 -0.330439 -1.882477  0.570032   \n",
       "#12          -0.027361  0.281791 -0.034381 -0.670752  0.183772 -1.114815   \n",
       "#100daystogo  0.279218 -0.179337  1.600295  0.917597 -1.725892 -0.180869   \n",
       "#100days      0.017074  0.000695  0.607982  0.539324 -1.133705 -0.923764   \n",
       "#100aday      0.830787  0.126167  0.080057  0.232088 -0.744568 -0.666176   \n",
       "\n",
       "                    12        13        14        15        16        17  \\\n",
       "<user>       -0.325759  0.023690 -0.068419 -0.138550  0.070042  0.004386   \n",
       "!            -0.436972  0.040640 -0.101456 -0.207414  0.105051  0.032727   \n",
       "i            -0.510677  0.015466 -0.134536 -0.312960  0.116450 -0.031302   \n",
       "you          -0.568887  0.027036 -0.187725 -0.365074  0.102648 -0.000199   \n",
       ".            -0.495331  0.044647 -0.146040 -0.302999  0.117209 -0.036188   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "#13          -0.948262  0.039559  0.739215 -0.962181 -1.530525  0.159301   \n",
       "#12           0.598311 -0.444628 -1.830605  0.519197 -0.322483  1.008614   \n",
       "#100daystogo  0.278357 -0.596489  0.018683  1.149776 -0.771335  0.552752   \n",
       "#100days      0.991551  0.108570  1.192866 -0.172446  0.771834  1.796897   \n",
       "#100aday     -0.013387 -0.392850 -0.151480  0.731952  1.196030 -0.953245   \n",
       "\n",
       "                    18        19  \n",
       "<user>        0.277096 -0.284308  \n",
       "!             0.334475 -0.351101  \n",
       "i             0.470830 -0.491612  \n",
       "you           0.510087 -0.503674  \n",
       ".             0.404599 -0.458328  \n",
       "...                ...       ...  \n",
       "#13          -1.720396  2.020875  \n",
       "#12           1.952389 -0.772046  \n",
       "#100daystogo  0.024422  0.559456  \n",
       "#100days     -0.545241 -0.575005  \n",
       "#100aday      1.958946  0.962804  \n",
       "\n",
       "[14179 rows x 20 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sea doo pro sea scooter ( sports with the port...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;user&gt; shucks well i work all week so now i ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>i cant stay away from bug thats my baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&lt;user&gt; no ma'am ! ! ! lol im perfectly fine an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>whenever i fall asleep watching the tv , i alw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>had a nice time w / my friend lastnite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>&lt;user&gt; no it's not ! please stop !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>not without my daughter ( dvd two-time oscar (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>&lt;user&gt; have fun in class sweetcheeks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>making a r . e . a . l . difference . ( get r ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets\n",
       "0     sea doo pro sea scooter ( sports with the port...\n",
       "1     <user> shucks well i work all week so now i ca...\n",
       "2               i cant stay away from bug thats my baby\n",
       "3     <user> no ma'am ! ! ! lol im perfectly fine an...\n",
       "4     whenever i fall asleep watching the tv , i alw...\n",
       "...                                                 ...\n",
       "9995             had a nice time w / my friend lastnite\n",
       "9996                 <user> no it's not ! please stop !\n",
       "9997  not without my daughter ( dvd two-time oscar (...\n",
       "9998               <user> have fun in class sweetcheeks\n",
       "9999  making a r . e . a . l . difference . ( get r ...\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data = pd.read_csv(\"../cleaned_data/test_sample_data.csv\")\n",
    "sample_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- construct a feature representation of each training tweet (by averaging the word vectors over all words of the tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_vectors(tweets ,word_embedding):\n",
    "    \n",
    "    error = 0\n",
    "    avg_word_vectors = np.zeros((len(tweets), word_embedding.shape[1] ))\n",
    "    for i, tweet in enumerate(tweets):\n",
    "        \n",
    "        split_tweet = tweet.split()\n",
    "        nb_words = 0\n",
    "        \n",
    "        for word in split_tweet:\n",
    "            try:\n",
    "                avg_word_vectors[i] += word_embedding_df.loc[word].to_numpy()\n",
    "                nb_words += 1\n",
    "\n",
    "            except KeyError: \n",
    "                continue\n",
    "        if (nb_words != 0):\n",
    "            avg_word_vectors[i] /= nb_words\n",
    "        \n",
    "    return avg_word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_word_vectors = average_word_vectors(sample_train_data.tweets ,word_embedding_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.103042</td>\n",
       "      <td>-0.476258</td>\n",
       "      <td>0.253031</td>\n",
       "      <td>0.271344</td>\n",
       "      <td>-0.234250</td>\n",
       "      <td>-0.416527</td>\n",
       "      <td>0.350542</td>\n",
       "      <td>-0.263698</td>\n",
       "      <td>-0.677710</td>\n",
       "      <td>-0.348175</td>\n",
       "      <td>0.754546</td>\n",
       "      <td>-0.523776</td>\n",
       "      <td>-0.105592</td>\n",
       "      <td>0.051636</td>\n",
       "      <td>-0.148467</td>\n",
       "      <td>-0.423588</td>\n",
       "      <td>0.114603</td>\n",
       "      <td>0.056566</td>\n",
       "      <td>0.458621</td>\n",
       "      <td>-0.648659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.035343</td>\n",
       "      <td>-0.202305</td>\n",
       "      <td>0.569880</td>\n",
       "      <td>0.655770</td>\n",
       "      <td>-0.230325</td>\n",
       "      <td>-0.277664</td>\n",
       "      <td>0.348995</td>\n",
       "      <td>-0.435550</td>\n",
       "      <td>-0.946713</td>\n",
       "      <td>-0.233682</td>\n",
       "      <td>0.562428</td>\n",
       "      <td>-0.594078</td>\n",
       "      <td>-0.487470</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>-0.177855</td>\n",
       "      <td>-0.337911</td>\n",
       "      <td>0.073457</td>\n",
       "      <td>-0.051864</td>\n",
       "      <td>0.510632</td>\n",
       "      <td>-0.386786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.063345</td>\n",
       "      <td>-0.098303</td>\n",
       "      <td>0.395130</td>\n",
       "      <td>0.665450</td>\n",
       "      <td>-0.270500</td>\n",
       "      <td>-0.271853</td>\n",
       "      <td>0.267416</td>\n",
       "      <td>-0.422232</td>\n",
       "      <td>-0.849598</td>\n",
       "      <td>-0.197942</td>\n",
       "      <td>0.555567</td>\n",
       "      <td>-0.544237</td>\n",
       "      <td>-0.445162</td>\n",
       "      <td>0.075814</td>\n",
       "      <td>-0.143498</td>\n",
       "      <td>-0.335021</td>\n",
       "      <td>0.127981</td>\n",
       "      <td>-0.023418</td>\n",
       "      <td>0.470948</td>\n",
       "      <td>-0.404352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.084570</td>\n",
       "      <td>-0.304171</td>\n",
       "      <td>0.542734</td>\n",
       "      <td>0.674538</td>\n",
       "      <td>-0.562034</td>\n",
       "      <td>0.114750</td>\n",
       "      <td>0.536907</td>\n",
       "      <td>-0.515769</td>\n",
       "      <td>-0.733989</td>\n",
       "      <td>-0.135776</td>\n",
       "      <td>0.503222</td>\n",
       "      <td>-0.618604</td>\n",
       "      <td>-0.227896</td>\n",
       "      <td>0.100328</td>\n",
       "      <td>-0.111213</td>\n",
       "      <td>-0.220813</td>\n",
       "      <td>-0.043338</td>\n",
       "      <td>-0.014036</td>\n",
       "      <td>0.076931</td>\n",
       "      <td>-0.208996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.133802</td>\n",
       "      <td>-0.171259</td>\n",
       "      <td>0.459780</td>\n",
       "      <td>0.583461</td>\n",
       "      <td>-0.156678</td>\n",
       "      <td>-0.284474</td>\n",
       "      <td>0.412175</td>\n",
       "      <td>-0.353415</td>\n",
       "      <td>-0.850640</td>\n",
       "      <td>-0.278544</td>\n",
       "      <td>0.375492</td>\n",
       "      <td>-0.668245</td>\n",
       "      <td>-0.434267</td>\n",
       "      <td>-0.042149</td>\n",
       "      <td>-0.051464</td>\n",
       "      <td>-0.364874</td>\n",
       "      <td>-0.020598</td>\n",
       "      <td>-0.126889</td>\n",
       "      <td>0.458288</td>\n",
       "      <td>-0.335189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199995</td>\n",
       "      <td>-0.153317</td>\n",
       "      <td>-0.185661</td>\n",
       "      <td>0.495620</td>\n",
       "      <td>0.516081</td>\n",
       "      <td>-0.258990</td>\n",
       "      <td>-0.348437</td>\n",
       "      <td>0.509613</td>\n",
       "      <td>-0.321200</td>\n",
       "      <td>-0.795003</td>\n",
       "      <td>-0.095673</td>\n",
       "      <td>0.428474</td>\n",
       "      <td>-0.540596</td>\n",
       "      <td>-0.459039</td>\n",
       "      <td>-0.074225</td>\n",
       "      <td>-0.094385</td>\n",
       "      <td>-0.147408</td>\n",
       "      <td>0.035848</td>\n",
       "      <td>-0.124784</td>\n",
       "      <td>0.258645</td>\n",
       "      <td>-0.516928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199996</td>\n",
       "      <td>-0.072823</td>\n",
       "      <td>-0.241911</td>\n",
       "      <td>0.320355</td>\n",
       "      <td>0.616920</td>\n",
       "      <td>-0.104754</td>\n",
       "      <td>-0.029998</td>\n",
       "      <td>0.192886</td>\n",
       "      <td>-0.748162</td>\n",
       "      <td>-0.665640</td>\n",
       "      <td>-0.080984</td>\n",
       "      <td>0.162043</td>\n",
       "      <td>-0.466616</td>\n",
       "      <td>-0.884462</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>-0.140857</td>\n",
       "      <td>-0.187924</td>\n",
       "      <td>-0.098489</td>\n",
       "      <td>0.249598</td>\n",
       "      <td>0.202039</td>\n",
       "      <td>-0.454237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199997</td>\n",
       "      <td>-0.019281</td>\n",
       "      <td>-0.097291</td>\n",
       "      <td>0.470629</td>\n",
       "      <td>0.571047</td>\n",
       "      <td>-0.230550</td>\n",
       "      <td>-0.210472</td>\n",
       "      <td>0.365973</td>\n",
       "      <td>-0.324163</td>\n",
       "      <td>-0.774482</td>\n",
       "      <td>-0.112376</td>\n",
       "      <td>0.514962</td>\n",
       "      <td>-0.677924</td>\n",
       "      <td>-0.422658</td>\n",
       "      <td>0.014096</td>\n",
       "      <td>-0.116945</td>\n",
       "      <td>-0.269073</td>\n",
       "      <td>0.021149</td>\n",
       "      <td>-0.033446</td>\n",
       "      <td>0.600041</td>\n",
       "      <td>-0.371906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199998</td>\n",
       "      <td>-0.126683</td>\n",
       "      <td>-0.128776</td>\n",
       "      <td>0.439913</td>\n",
       "      <td>0.545141</td>\n",
       "      <td>-0.262770</td>\n",
       "      <td>-0.251818</td>\n",
       "      <td>0.208687</td>\n",
       "      <td>-0.350087</td>\n",
       "      <td>-0.787578</td>\n",
       "      <td>-0.232098</td>\n",
       "      <td>0.456932</td>\n",
       "      <td>-0.437572</td>\n",
       "      <td>-0.415643</td>\n",
       "      <td>0.034471</td>\n",
       "      <td>-0.173846</td>\n",
       "      <td>-0.294360</td>\n",
       "      <td>0.129467</td>\n",
       "      <td>-0.073206</td>\n",
       "      <td>0.416882</td>\n",
       "      <td>-0.499365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199999</td>\n",
       "      <td>0.020030</td>\n",
       "      <td>-0.180040</td>\n",
       "      <td>0.681586</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>-0.316719</td>\n",
       "      <td>-0.337844</td>\n",
       "      <td>0.395549</td>\n",
       "      <td>-0.492933</td>\n",
       "      <td>-0.946782</td>\n",
       "      <td>-0.294724</td>\n",
       "      <td>0.507040</td>\n",
       "      <td>-0.570539</td>\n",
       "      <td>-0.403188</td>\n",
       "      <td>0.050697</td>\n",
       "      <td>-0.103974</td>\n",
       "      <td>-0.256312</td>\n",
       "      <td>0.197559</td>\n",
       "      <td>-0.154216</td>\n",
       "      <td>0.414692</td>\n",
       "      <td>-0.487159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "0       0.103042 -0.476258  0.253031  0.271344 -0.234250 -0.416527  0.350542   \n",
       "1      -0.035343 -0.202305  0.569880  0.655770 -0.230325 -0.277664  0.348995   \n",
       "2      -0.063345 -0.098303  0.395130  0.665450 -0.270500 -0.271853  0.267416   \n",
       "3       0.084570 -0.304171  0.542734  0.674538 -0.562034  0.114750  0.536907   \n",
       "4      -0.133802 -0.171259  0.459780  0.583461 -0.156678 -0.284474  0.412175   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "199995 -0.153317 -0.185661  0.495620  0.516081 -0.258990 -0.348437  0.509613   \n",
       "199996 -0.072823 -0.241911  0.320355  0.616920 -0.104754 -0.029998  0.192886   \n",
       "199997 -0.019281 -0.097291  0.470629  0.571047 -0.230550 -0.210472  0.365973   \n",
       "199998 -0.126683 -0.128776  0.439913  0.545141 -0.262770 -0.251818  0.208687   \n",
       "199999  0.020030 -0.180040  0.681586  0.507066 -0.316719 -0.337844  0.395549   \n",
       "\n",
       "               7         8         9        10        11        12        13  \\\n",
       "0      -0.263698 -0.677710 -0.348175  0.754546 -0.523776 -0.105592  0.051636   \n",
       "1      -0.435550 -0.946713 -0.233682  0.562428 -0.594078 -0.487470  0.059900   \n",
       "2      -0.422232 -0.849598 -0.197942  0.555567 -0.544237 -0.445162  0.075814   \n",
       "3      -0.515769 -0.733989 -0.135776  0.503222 -0.618604 -0.227896  0.100328   \n",
       "4      -0.353415 -0.850640 -0.278544  0.375492 -0.668245 -0.434267 -0.042149   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "199995 -0.321200 -0.795003 -0.095673  0.428474 -0.540596 -0.459039 -0.074225   \n",
       "199996 -0.748162 -0.665640 -0.080984  0.162043 -0.466616 -0.884462  0.012675   \n",
       "199997 -0.324163 -0.774482 -0.112376  0.514962 -0.677924 -0.422658  0.014096   \n",
       "199998 -0.350087 -0.787578 -0.232098  0.456932 -0.437572 -0.415643  0.034471   \n",
       "199999 -0.492933 -0.946782 -0.294724  0.507040 -0.570539 -0.403188  0.050697   \n",
       "\n",
       "              14        15        16        17        18        19  \n",
       "0      -0.148467 -0.423588  0.114603  0.056566  0.458621 -0.648659  \n",
       "1      -0.177855 -0.337911  0.073457 -0.051864  0.510632 -0.386786  \n",
       "2      -0.143498 -0.335021  0.127981 -0.023418  0.470948 -0.404352  \n",
       "3      -0.111213 -0.220813 -0.043338 -0.014036  0.076931 -0.208996  \n",
       "4      -0.051464 -0.364874 -0.020598 -0.126889  0.458288 -0.335189  \n",
       "...          ...       ...       ...       ...       ...       ...  \n",
       "199995 -0.094385 -0.147408  0.035848 -0.124784  0.258645 -0.516928  \n",
       "199996 -0.140857 -0.187924 -0.098489  0.249598  0.202039 -0.454237  \n",
       "199997 -0.116945 -0.269073  0.021149 -0.033446  0.600041 -0.371906  \n",
       "199998 -0.173846 -0.294360  0.129467 -0.073206  0.416882 -0.499365  \n",
       "199999 -0.103974 -0.256312  0.197559 -0.154216  0.414692 -0.487159  \n",
       "\n",
       "[200000 rows x 20 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_word_vectors_df = pd.DataFrame(avg_word_vectors)\n",
    "avg_word_vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sign</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ayee tell em ' bitches to come through</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103042</td>\n",
       "      <td>-0.476258</td>\n",
       "      <td>0.253031</td>\n",
       "      <td>0.271344</td>\n",
       "      <td>-0.234250</td>\n",
       "      <td>-0.416527</td>\n",
       "      <td>0.350542</td>\n",
       "      <td>-0.263698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754546</td>\n",
       "      <td>-0.523776</td>\n",
       "      <td>-0.105592</td>\n",
       "      <td>0.051636</td>\n",
       "      <td>-0.148467</td>\n",
       "      <td>-0.423588</td>\n",
       "      <td>0.114603</td>\n",
       "      <td>0.056566</td>\n",
       "      <td>0.458621</td>\n",
       "      <td>-0.648659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; congrats on making it dude  laug...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.035343</td>\n",
       "      <td>-0.202305</td>\n",
       "      <td>0.569880</td>\n",
       "      <td>0.655770</td>\n",
       "      <td>-0.230325</td>\n",
       "      <td>-0.277664</td>\n",
       "      <td>0.348995</td>\n",
       "      <td>-0.435550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562428</td>\n",
       "      <td>-0.594078</td>\n",
       "      <td>-0.487470</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>-0.177855</td>\n",
       "      <td>-0.337911</td>\n",
       "      <td>0.073457</td>\n",
       "      <td>-0.051864</td>\n",
       "      <td>0.510632</td>\n",
       "      <td>-0.386786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>&lt;user&gt; yes ! i'd love to show you guys around ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.063345</td>\n",
       "      <td>-0.098303</td>\n",
       "      <td>0.395130</td>\n",
       "      <td>0.665450</td>\n",
       "      <td>-0.270500</td>\n",
       "      <td>-0.271853</td>\n",
       "      <td>0.267416</td>\n",
       "      <td>-0.422232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555567</td>\n",
       "      <td>-0.544237</td>\n",
       "      <td>-0.445162</td>\n",
       "      <td>0.075814</td>\n",
       "      <td>-0.143498</td>\n",
       "      <td>-0.335021</td>\n",
       "      <td>0.127981</td>\n",
       "      <td>-0.023418</td>\n",
       "      <td>0.470948</td>\n",
       "      <td>-0.404352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&lt;user&gt; we'll maybe meet there - bianca</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084570</td>\n",
       "      <td>-0.304171</td>\n",
       "      <td>0.542734</td>\n",
       "      <td>0.674538</td>\n",
       "      <td>-0.562034</td>\n",
       "      <td>0.114750</td>\n",
       "      <td>0.536907</td>\n",
       "      <td>-0.515769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503222</td>\n",
       "      <td>-0.618604</td>\n",
       "      <td>-0.227896</td>\n",
       "      <td>0.100328</td>\n",
       "      <td>-0.111213</td>\n",
       "      <td>-0.220813</td>\n",
       "      <td>-0.043338</td>\n",
       "      <td>-0.014036</td>\n",
       "      <td>0.076931</td>\n",
       "      <td>-0.208996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>&lt;user&gt; hello snooki follow me back please ? i ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.133802</td>\n",
       "      <td>-0.171259</td>\n",
       "      <td>0.459780</td>\n",
       "      <td>0.583461</td>\n",
       "      <td>-0.156678</td>\n",
       "      <td>-0.284474</td>\n",
       "      <td>0.412175</td>\n",
       "      <td>-0.353415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375492</td>\n",
       "      <td>-0.668245</td>\n",
       "      <td>-0.434267</td>\n",
       "      <td>-0.042149</td>\n",
       "      <td>-0.051464</td>\n",
       "      <td>-0.364874</td>\n",
       "      <td>-0.020598</td>\n",
       "      <td>-0.126889</td>\n",
       "      <td>0.458288</td>\n",
       "      <td>-0.335189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199995</td>\n",
       "      <td>&lt;user&gt; your a loser  wink  p hahahaha i'm not ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.153317</td>\n",
       "      <td>-0.185661</td>\n",
       "      <td>0.495620</td>\n",
       "      <td>0.516081</td>\n",
       "      <td>-0.258990</td>\n",
       "      <td>-0.348437</td>\n",
       "      <td>0.509613</td>\n",
       "      <td>-0.321200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428474</td>\n",
       "      <td>-0.540596</td>\n",
       "      <td>-0.459039</td>\n",
       "      <td>-0.074225</td>\n",
       "      <td>-0.094385</td>\n",
       "      <td>-0.147408</td>\n",
       "      <td>0.035848</td>\n",
       "      <td>-0.124784</td>\n",
       "      <td>0.258645</td>\n",
       "      <td>-0.516928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199996</td>\n",
       "      <td>&lt;user&gt; he said thankyou</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.072823</td>\n",
       "      <td>-0.241911</td>\n",
       "      <td>0.320355</td>\n",
       "      <td>0.616920</td>\n",
       "      <td>-0.104754</td>\n",
       "      <td>-0.029998</td>\n",
       "      <td>0.192886</td>\n",
       "      <td>-0.748162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162043</td>\n",
       "      <td>-0.466616</td>\n",
       "      <td>-0.884462</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>-0.140857</td>\n",
       "      <td>-0.187924</td>\n",
       "      <td>-0.098489</td>\n",
       "      <td>0.249598</td>\n",
       "      <td>0.202039</td>\n",
       "      <td>-0.454237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199997</td>\n",
       "      <td>&lt;user&gt; i'll do national exam on monday till th...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.019281</td>\n",
       "      <td>-0.097291</td>\n",
       "      <td>0.470629</td>\n",
       "      <td>0.571047</td>\n",
       "      <td>-0.230550</td>\n",
       "      <td>-0.210472</td>\n",
       "      <td>0.365973</td>\n",
       "      <td>-0.324163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514962</td>\n",
       "      <td>-0.677924</td>\n",
       "      <td>-0.422658</td>\n",
       "      <td>0.014096</td>\n",
       "      <td>-0.116945</td>\n",
       "      <td>-0.269073</td>\n",
       "      <td>0.021149</td>\n",
       "      <td>-0.033446</td>\n",
       "      <td>0.600041</td>\n",
       "      <td>-0.371906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199998</td>\n",
       "      <td>&lt;user&gt; ready .. set .. here we go ! ! ! &lt;user&gt;...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.126683</td>\n",
       "      <td>-0.128776</td>\n",
       "      <td>0.439913</td>\n",
       "      <td>0.545141</td>\n",
       "      <td>-0.262770</td>\n",
       "      <td>-0.251818</td>\n",
       "      <td>0.208687</td>\n",
       "      <td>-0.350087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456932</td>\n",
       "      <td>-0.437572</td>\n",
       "      <td>-0.415643</td>\n",
       "      <td>0.034471</td>\n",
       "      <td>-0.173846</td>\n",
       "      <td>-0.294360</td>\n",
       "      <td>0.129467</td>\n",
       "      <td>-0.073206</td>\n",
       "      <td>0.416882</td>\n",
       "      <td>-0.499365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199999</td>\n",
       "      <td>&lt;user&gt; im good . just about to have breakfast</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020030</td>\n",
       "      <td>-0.180040</td>\n",
       "      <td>0.681586</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>-0.316719</td>\n",
       "      <td>-0.337844</td>\n",
       "      <td>0.395549</td>\n",
       "      <td>-0.492933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507040</td>\n",
       "      <td>-0.570539</td>\n",
       "      <td>-0.403188</td>\n",
       "      <td>0.050697</td>\n",
       "      <td>-0.103974</td>\n",
       "      <td>-0.256312</td>\n",
       "      <td>0.197559</td>\n",
       "      <td>-0.154216</td>\n",
       "      <td>0.414692</td>\n",
       "      <td>-0.487159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweets  sign         0  \\\n",
       "0                  ayee tell em ' bitches to come through   0.0  0.103042   \n",
       "1       <user> <user> congrats on making it dude  laug...   1.0 -0.035343   \n",
       "2       <user> yes ! i'd love to show you guys around ...   1.0 -0.063345   \n",
       "3                  <user> we'll maybe meet there - bianca   0.0  0.084570   \n",
       "4       <user> hello snooki follow me back please ? i ...   0.0 -0.133802   \n",
       "...                                                   ...   ...       ...   \n",
       "199995  <user> your a loser  wink  p hahahaha i'm not ...   1.0 -0.153317   \n",
       "199996                            <user> he said thankyou   1.0 -0.072823   \n",
       "199997  <user> i'll do national exam on monday till th...   1.0 -0.019281   \n",
       "199998  <user> ready .. set .. here we go ! ! ! <user>...   0.0 -0.126683   \n",
       "199999      <user> im good . just about to have breakfast   0.0  0.020030   \n",
       "\n",
       "               1         2         3         4         5         6         7  \\\n",
       "0      -0.476258  0.253031  0.271344 -0.234250 -0.416527  0.350542 -0.263698   \n",
       "1      -0.202305  0.569880  0.655770 -0.230325 -0.277664  0.348995 -0.435550   \n",
       "2      -0.098303  0.395130  0.665450 -0.270500 -0.271853  0.267416 -0.422232   \n",
       "3      -0.304171  0.542734  0.674538 -0.562034  0.114750  0.536907 -0.515769   \n",
       "4      -0.171259  0.459780  0.583461 -0.156678 -0.284474  0.412175 -0.353415   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "199995 -0.185661  0.495620  0.516081 -0.258990 -0.348437  0.509613 -0.321200   \n",
       "199996 -0.241911  0.320355  0.616920 -0.104754 -0.029998  0.192886 -0.748162   \n",
       "199997 -0.097291  0.470629  0.571047 -0.230550 -0.210472  0.365973 -0.324163   \n",
       "199998 -0.128776  0.439913  0.545141 -0.262770 -0.251818  0.208687 -0.350087   \n",
       "199999 -0.180040  0.681586  0.507066 -0.316719 -0.337844  0.395549 -0.492933   \n",
       "\n",
       "        ...        10        11        12        13        14        15  \\\n",
       "0       ...  0.754546 -0.523776 -0.105592  0.051636 -0.148467 -0.423588   \n",
       "1       ...  0.562428 -0.594078 -0.487470  0.059900 -0.177855 -0.337911   \n",
       "2       ...  0.555567 -0.544237 -0.445162  0.075814 -0.143498 -0.335021   \n",
       "3       ...  0.503222 -0.618604 -0.227896  0.100328 -0.111213 -0.220813   \n",
       "4       ...  0.375492 -0.668245 -0.434267 -0.042149 -0.051464 -0.364874   \n",
       "...     ...       ...       ...       ...       ...       ...       ...   \n",
       "199995  ...  0.428474 -0.540596 -0.459039 -0.074225 -0.094385 -0.147408   \n",
       "199996  ...  0.162043 -0.466616 -0.884462  0.012675 -0.140857 -0.187924   \n",
       "199997  ...  0.514962 -0.677924 -0.422658  0.014096 -0.116945 -0.269073   \n",
       "199998  ...  0.456932 -0.437572 -0.415643  0.034471 -0.173846 -0.294360   \n",
       "199999  ...  0.507040 -0.570539 -0.403188  0.050697 -0.103974 -0.256312   \n",
       "\n",
       "              16        17        18        19  \n",
       "0       0.114603  0.056566  0.458621 -0.648659  \n",
       "1       0.073457 -0.051864  0.510632 -0.386786  \n",
       "2       0.127981 -0.023418  0.470948 -0.404352  \n",
       "3      -0.043338 -0.014036  0.076931 -0.208996  \n",
       "4      -0.020598 -0.126889  0.458288 -0.335189  \n",
       "...          ...       ...       ...       ...  \n",
       "199995  0.035848 -0.124784  0.258645 -0.516928  \n",
       "199996 -0.098489  0.249598  0.202039 -0.454237  \n",
       "199997  0.021149 -0.033446  0.600041 -0.371906  \n",
       "199998  0.129467 -0.073206  0.416882 -0.499365  \n",
       "199999  0.197559 -0.154216  0.414692 -0.487159  \n",
       "\n",
       "[200000 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_train_word_vectors = pd.concat([sample_train_data,avg_word_vectors_df],axis=1)\n",
    "sample_train_word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.103042</td>\n",
       "      <td>-0.476258</td>\n",
       "      <td>0.253031</td>\n",
       "      <td>0.271344</td>\n",
       "      <td>-0.234250</td>\n",
       "      <td>-0.416527</td>\n",
       "      <td>0.350542</td>\n",
       "      <td>-0.263698</td>\n",
       "      <td>-0.677710</td>\n",
       "      <td>-0.348175</td>\n",
       "      <td>0.754546</td>\n",
       "      <td>-0.523776</td>\n",
       "      <td>-0.105592</td>\n",
       "      <td>0.051636</td>\n",
       "      <td>-0.148467</td>\n",
       "      <td>-0.423588</td>\n",
       "      <td>0.114603</td>\n",
       "      <td>0.056566</td>\n",
       "      <td>0.458621</td>\n",
       "      <td>-0.648659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.035343</td>\n",
       "      <td>-0.202305</td>\n",
       "      <td>0.569880</td>\n",
       "      <td>0.655770</td>\n",
       "      <td>-0.230325</td>\n",
       "      <td>-0.277664</td>\n",
       "      <td>0.348995</td>\n",
       "      <td>-0.435550</td>\n",
       "      <td>-0.946713</td>\n",
       "      <td>-0.233682</td>\n",
       "      <td>0.562428</td>\n",
       "      <td>-0.594078</td>\n",
       "      <td>-0.487470</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>-0.177855</td>\n",
       "      <td>-0.337911</td>\n",
       "      <td>0.073457</td>\n",
       "      <td>-0.051864</td>\n",
       "      <td>0.510632</td>\n",
       "      <td>-0.386786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.063345</td>\n",
       "      <td>-0.098303</td>\n",
       "      <td>0.395130</td>\n",
       "      <td>0.665450</td>\n",
       "      <td>-0.270500</td>\n",
       "      <td>-0.271853</td>\n",
       "      <td>0.267416</td>\n",
       "      <td>-0.422232</td>\n",
       "      <td>-0.849598</td>\n",
       "      <td>-0.197942</td>\n",
       "      <td>0.555567</td>\n",
       "      <td>-0.544237</td>\n",
       "      <td>-0.445162</td>\n",
       "      <td>0.075814</td>\n",
       "      <td>-0.143498</td>\n",
       "      <td>-0.335021</td>\n",
       "      <td>0.127981</td>\n",
       "      <td>-0.023418</td>\n",
       "      <td>0.470948</td>\n",
       "      <td>-0.404352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.084570</td>\n",
       "      <td>-0.304171</td>\n",
       "      <td>0.542734</td>\n",
       "      <td>0.674538</td>\n",
       "      <td>-0.562034</td>\n",
       "      <td>0.114750</td>\n",
       "      <td>0.536907</td>\n",
       "      <td>-0.515769</td>\n",
       "      <td>-0.733989</td>\n",
       "      <td>-0.135776</td>\n",
       "      <td>0.503222</td>\n",
       "      <td>-0.618604</td>\n",
       "      <td>-0.227896</td>\n",
       "      <td>0.100328</td>\n",
       "      <td>-0.111213</td>\n",
       "      <td>-0.220813</td>\n",
       "      <td>-0.043338</td>\n",
       "      <td>-0.014036</td>\n",
       "      <td>0.076931</td>\n",
       "      <td>-0.208996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.133802</td>\n",
       "      <td>-0.171259</td>\n",
       "      <td>0.459780</td>\n",
       "      <td>0.583461</td>\n",
       "      <td>-0.156678</td>\n",
       "      <td>-0.284474</td>\n",
       "      <td>0.412175</td>\n",
       "      <td>-0.353415</td>\n",
       "      <td>-0.850640</td>\n",
       "      <td>-0.278544</td>\n",
       "      <td>0.375492</td>\n",
       "      <td>-0.668245</td>\n",
       "      <td>-0.434267</td>\n",
       "      <td>-0.042149</td>\n",
       "      <td>-0.051464</td>\n",
       "      <td>-0.364874</td>\n",
       "      <td>-0.020598</td>\n",
       "      <td>-0.126889</td>\n",
       "      <td>0.458288</td>\n",
       "      <td>-0.335189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199995</td>\n",
       "      <td>-0.153317</td>\n",
       "      <td>-0.185661</td>\n",
       "      <td>0.495620</td>\n",
       "      <td>0.516081</td>\n",
       "      <td>-0.258990</td>\n",
       "      <td>-0.348437</td>\n",
       "      <td>0.509613</td>\n",
       "      <td>-0.321200</td>\n",
       "      <td>-0.795003</td>\n",
       "      <td>-0.095673</td>\n",
       "      <td>0.428474</td>\n",
       "      <td>-0.540596</td>\n",
       "      <td>-0.459039</td>\n",
       "      <td>-0.074225</td>\n",
       "      <td>-0.094385</td>\n",
       "      <td>-0.147408</td>\n",
       "      <td>0.035848</td>\n",
       "      <td>-0.124784</td>\n",
       "      <td>0.258645</td>\n",
       "      <td>-0.516928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199996</td>\n",
       "      <td>-0.072823</td>\n",
       "      <td>-0.241911</td>\n",
       "      <td>0.320355</td>\n",
       "      <td>0.616920</td>\n",
       "      <td>-0.104754</td>\n",
       "      <td>-0.029998</td>\n",
       "      <td>0.192886</td>\n",
       "      <td>-0.748162</td>\n",
       "      <td>-0.665640</td>\n",
       "      <td>-0.080984</td>\n",
       "      <td>0.162043</td>\n",
       "      <td>-0.466616</td>\n",
       "      <td>-0.884462</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>-0.140857</td>\n",
       "      <td>-0.187924</td>\n",
       "      <td>-0.098489</td>\n",
       "      <td>0.249598</td>\n",
       "      <td>0.202039</td>\n",
       "      <td>-0.454237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199997</td>\n",
       "      <td>-0.019281</td>\n",
       "      <td>-0.097291</td>\n",
       "      <td>0.470629</td>\n",
       "      <td>0.571047</td>\n",
       "      <td>-0.230550</td>\n",
       "      <td>-0.210472</td>\n",
       "      <td>0.365973</td>\n",
       "      <td>-0.324163</td>\n",
       "      <td>-0.774482</td>\n",
       "      <td>-0.112376</td>\n",
       "      <td>0.514962</td>\n",
       "      <td>-0.677924</td>\n",
       "      <td>-0.422658</td>\n",
       "      <td>0.014096</td>\n",
       "      <td>-0.116945</td>\n",
       "      <td>-0.269073</td>\n",
       "      <td>0.021149</td>\n",
       "      <td>-0.033446</td>\n",
       "      <td>0.600041</td>\n",
       "      <td>-0.371906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199998</td>\n",
       "      <td>-0.126683</td>\n",
       "      <td>-0.128776</td>\n",
       "      <td>0.439913</td>\n",
       "      <td>0.545141</td>\n",
       "      <td>-0.262770</td>\n",
       "      <td>-0.251818</td>\n",
       "      <td>0.208687</td>\n",
       "      <td>-0.350087</td>\n",
       "      <td>-0.787578</td>\n",
       "      <td>-0.232098</td>\n",
       "      <td>0.456932</td>\n",
       "      <td>-0.437572</td>\n",
       "      <td>-0.415643</td>\n",
       "      <td>0.034471</td>\n",
       "      <td>-0.173846</td>\n",
       "      <td>-0.294360</td>\n",
       "      <td>0.129467</td>\n",
       "      <td>-0.073206</td>\n",
       "      <td>0.416882</td>\n",
       "      <td>-0.499365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199999</td>\n",
       "      <td>0.020030</td>\n",
       "      <td>-0.180040</td>\n",
       "      <td>0.681586</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>-0.316719</td>\n",
       "      <td>-0.337844</td>\n",
       "      <td>0.395549</td>\n",
       "      <td>-0.492933</td>\n",
       "      <td>-0.946782</td>\n",
       "      <td>-0.294724</td>\n",
       "      <td>0.507040</td>\n",
       "      <td>-0.570539</td>\n",
       "      <td>-0.403188</td>\n",
       "      <td>0.050697</td>\n",
       "      <td>-0.103974</td>\n",
       "      <td>-0.256312</td>\n",
       "      <td>0.197559</td>\n",
       "      <td>-0.154216</td>\n",
       "      <td>0.414692</td>\n",
       "      <td>-0.487159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "0       0.103042 -0.476258  0.253031  0.271344 -0.234250 -0.416527  0.350542   \n",
       "1      -0.035343 -0.202305  0.569880  0.655770 -0.230325 -0.277664  0.348995   \n",
       "2      -0.063345 -0.098303  0.395130  0.665450 -0.270500 -0.271853  0.267416   \n",
       "3       0.084570 -0.304171  0.542734  0.674538 -0.562034  0.114750  0.536907   \n",
       "4      -0.133802 -0.171259  0.459780  0.583461 -0.156678 -0.284474  0.412175   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "199995 -0.153317 -0.185661  0.495620  0.516081 -0.258990 -0.348437  0.509613   \n",
       "199996 -0.072823 -0.241911  0.320355  0.616920 -0.104754 -0.029998  0.192886   \n",
       "199997 -0.019281 -0.097291  0.470629  0.571047 -0.230550 -0.210472  0.365973   \n",
       "199998 -0.126683 -0.128776  0.439913  0.545141 -0.262770 -0.251818  0.208687   \n",
       "199999  0.020030 -0.180040  0.681586  0.507066 -0.316719 -0.337844  0.395549   \n",
       "\n",
       "              7         8         9         10        11        12        13  \\\n",
       "0      -0.263698 -0.677710 -0.348175  0.754546 -0.523776 -0.105592  0.051636   \n",
       "1      -0.435550 -0.946713 -0.233682  0.562428 -0.594078 -0.487470  0.059900   \n",
       "2      -0.422232 -0.849598 -0.197942  0.555567 -0.544237 -0.445162  0.075814   \n",
       "3      -0.515769 -0.733989 -0.135776  0.503222 -0.618604 -0.227896  0.100328   \n",
       "4      -0.353415 -0.850640 -0.278544  0.375492 -0.668245 -0.434267 -0.042149   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "199995 -0.321200 -0.795003 -0.095673  0.428474 -0.540596 -0.459039 -0.074225   \n",
       "199996 -0.748162 -0.665640 -0.080984  0.162043 -0.466616 -0.884462  0.012675   \n",
       "199997 -0.324163 -0.774482 -0.112376  0.514962 -0.677924 -0.422658  0.014096   \n",
       "199998 -0.350087 -0.787578 -0.232098  0.456932 -0.437572 -0.415643  0.034471   \n",
       "199999 -0.492933 -0.946782 -0.294724  0.507040 -0.570539 -0.403188  0.050697   \n",
       "\n",
       "              14        15        16        17        18        19  \n",
       "0      -0.148467 -0.423588  0.114603  0.056566  0.458621 -0.648659  \n",
       "1      -0.177855 -0.337911  0.073457 -0.051864  0.510632 -0.386786  \n",
       "2      -0.143498 -0.335021  0.127981 -0.023418  0.470948 -0.404352  \n",
       "3      -0.111213 -0.220813 -0.043338 -0.014036  0.076931 -0.208996  \n",
       "4      -0.051464 -0.364874 -0.020598 -0.126889  0.458288 -0.335189  \n",
       "...          ...       ...       ...       ...       ...       ...  \n",
       "199995 -0.094385 -0.147408  0.035848 -0.124784  0.258645 -0.516928  \n",
       "199996 -0.140857 -0.187924 -0.098489  0.249598  0.202039 -0.454237  \n",
       "199997 -0.116945 -0.269073  0.021149 -0.033446  0.600041 -0.371906  \n",
       "199998 -0.173846 -0.294360  0.129467 -0.073206  0.416882 -0.499365  \n",
       "199999 -0.103974 -0.256312  0.197559 -0.154216  0.414692 -0.487159  \n",
       "\n",
       "[200000 rows x 20 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = sample_train_word_vectors.drop(columns=[\"tweets\",\"sign\"])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = sample_train_word_vectors.sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sample_test_data\n",
    "avg_word_vectors_test_df = pd.DataFrame(average_word_vectors(X_test.tweets ,word_embedding_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.192925</td>\n",
       "      <td>-0.227320</td>\n",
       "      <td>0.531938</td>\n",
       "      <td>0.547458</td>\n",
       "      <td>-0.029546</td>\n",
       "      <td>-0.112131</td>\n",
       "      <td>0.177535</td>\n",
       "      <td>-0.155894</td>\n",
       "      <td>-0.665188</td>\n",
       "      <td>-0.311368</td>\n",
       "      <td>0.471397</td>\n",
       "      <td>-0.581751</td>\n",
       "      <td>-0.310495</td>\n",
       "      <td>0.047058</td>\n",
       "      <td>-0.352483</td>\n",
       "      <td>-0.348064</td>\n",
       "      <td>-0.194387</td>\n",
       "      <td>0.024943</td>\n",
       "      <td>0.149389</td>\n",
       "      <td>-0.378988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.105737</td>\n",
       "      <td>-0.160767</td>\n",
       "      <td>0.398062</td>\n",
       "      <td>0.659159</td>\n",
       "      <td>-0.267791</td>\n",
       "      <td>-0.235236</td>\n",
       "      <td>0.306701</td>\n",
       "      <td>-0.476188</td>\n",
       "      <td>-0.857286</td>\n",
       "      <td>-0.217737</td>\n",
       "      <td>0.459439</td>\n",
       "      <td>-0.639661</td>\n",
       "      <td>-0.425403</td>\n",
       "      <td>0.047152</td>\n",
       "      <td>-0.127996</td>\n",
       "      <td>-0.273561</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>-0.089354</td>\n",
       "      <td>0.513522</td>\n",
       "      <td>-0.313904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.035192</td>\n",
       "      <td>-0.152306</td>\n",
       "      <td>0.482523</td>\n",
       "      <td>0.457505</td>\n",
       "      <td>-0.015983</td>\n",
       "      <td>-0.144561</td>\n",
       "      <td>0.206993</td>\n",
       "      <td>-0.505070</td>\n",
       "      <td>-0.737938</td>\n",
       "      <td>-0.413103</td>\n",
       "      <td>0.552791</td>\n",
       "      <td>-0.428667</td>\n",
       "      <td>-0.335365</td>\n",
       "      <td>0.081298</td>\n",
       "      <td>-0.249936</td>\n",
       "      <td>-0.276294</td>\n",
       "      <td>0.036955</td>\n",
       "      <td>-0.213982</td>\n",
       "      <td>0.603942</td>\n",
       "      <td>-0.422719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.177934</td>\n",
       "      <td>-0.083295</td>\n",
       "      <td>0.252004</td>\n",
       "      <td>0.577131</td>\n",
       "      <td>-0.376043</td>\n",
       "      <td>-0.251949</td>\n",
       "      <td>0.409394</td>\n",
       "      <td>-0.171015</td>\n",
       "      <td>-0.630986</td>\n",
       "      <td>-0.157952</td>\n",
       "      <td>0.465188</td>\n",
       "      <td>-0.520418</td>\n",
       "      <td>-0.268709</td>\n",
       "      <td>-0.060737</td>\n",
       "      <td>-0.092826</td>\n",
       "      <td>-0.208967</td>\n",
       "      <td>0.056133</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.443746</td>\n",
       "      <td>-0.446448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.160648</td>\n",
       "      <td>-0.184098</td>\n",
       "      <td>0.346441</td>\n",
       "      <td>0.410458</td>\n",
       "      <td>-0.224065</td>\n",
       "      <td>-0.253801</td>\n",
       "      <td>0.338415</td>\n",
       "      <td>-0.520747</td>\n",
       "      <td>-0.698456</td>\n",
       "      <td>-0.148005</td>\n",
       "      <td>0.401808</td>\n",
       "      <td>-0.487821</td>\n",
       "      <td>-0.459717</td>\n",
       "      <td>0.068937</td>\n",
       "      <td>-0.204519</td>\n",
       "      <td>-0.150342</td>\n",
       "      <td>0.097417</td>\n",
       "      <td>-0.137441</td>\n",
       "      <td>0.448936</td>\n",
       "      <td>-0.506880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>-0.063082</td>\n",
       "      <td>-0.126341</td>\n",
       "      <td>0.437498</td>\n",
       "      <td>0.675349</td>\n",
       "      <td>-0.300340</td>\n",
       "      <td>-0.314575</td>\n",
       "      <td>0.332507</td>\n",
       "      <td>-0.538570</td>\n",
       "      <td>-0.920960</td>\n",
       "      <td>-0.224309</td>\n",
       "      <td>0.603431</td>\n",
       "      <td>-0.625257</td>\n",
       "      <td>-0.436727</td>\n",
       "      <td>0.074245</td>\n",
       "      <td>-0.158525</td>\n",
       "      <td>-0.282326</td>\n",
       "      <td>0.140544</td>\n",
       "      <td>-0.080999</td>\n",
       "      <td>0.492803</td>\n",
       "      <td>-0.425586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>-0.083859</td>\n",
       "      <td>-0.111094</td>\n",
       "      <td>0.420981</td>\n",
       "      <td>0.631187</td>\n",
       "      <td>-0.279325</td>\n",
       "      <td>-0.222907</td>\n",
       "      <td>0.283491</td>\n",
       "      <td>-0.420281</td>\n",
       "      <td>-0.893414</td>\n",
       "      <td>-0.182745</td>\n",
       "      <td>0.518702</td>\n",
       "      <td>-0.514142</td>\n",
       "      <td>-0.476802</td>\n",
       "      <td>0.043555</td>\n",
       "      <td>-0.162426</td>\n",
       "      <td>-0.252175</td>\n",
       "      <td>0.056786</td>\n",
       "      <td>-0.050622</td>\n",
       "      <td>0.423405</td>\n",
       "      <td>-0.484523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>-0.125323</td>\n",
       "      <td>-0.205932</td>\n",
       "      <td>0.365661</td>\n",
       "      <td>0.434190</td>\n",
       "      <td>-0.104743</td>\n",
       "      <td>-0.125283</td>\n",
       "      <td>0.429559</td>\n",
       "      <td>-0.431185</td>\n",
       "      <td>-0.609905</td>\n",
       "      <td>-0.132508</td>\n",
       "      <td>0.499256</td>\n",
       "      <td>-0.596574</td>\n",
       "      <td>-0.356582</td>\n",
       "      <td>-0.122496</td>\n",
       "      <td>0.102354</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.267052</td>\n",
       "      <td>0.113557</td>\n",
       "      <td>0.425755</td>\n",
       "      <td>-0.410532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>-0.110458</td>\n",
       "      <td>-0.105682</td>\n",
       "      <td>0.404172</td>\n",
       "      <td>0.537259</td>\n",
       "      <td>-0.262631</td>\n",
       "      <td>-0.320473</td>\n",
       "      <td>0.374739</td>\n",
       "      <td>-0.496816</td>\n",
       "      <td>-0.904411</td>\n",
       "      <td>-0.249470</td>\n",
       "      <td>0.433276</td>\n",
       "      <td>-0.496582</td>\n",
       "      <td>-0.509667</td>\n",
       "      <td>0.079502</td>\n",
       "      <td>-0.078198</td>\n",
       "      <td>-0.354974</td>\n",
       "      <td>0.131434</td>\n",
       "      <td>0.049244</td>\n",
       "      <td>0.507311</td>\n",
       "      <td>-0.418555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>-0.023008</td>\n",
       "      <td>-0.196995</td>\n",
       "      <td>0.479772</td>\n",
       "      <td>0.603899</td>\n",
       "      <td>-0.260130</td>\n",
       "      <td>-0.093538</td>\n",
       "      <td>0.142174</td>\n",
       "      <td>-0.301749</td>\n",
       "      <td>-0.832235</td>\n",
       "      <td>-0.303246</td>\n",
       "      <td>0.497656</td>\n",
       "      <td>-0.399801</td>\n",
       "      <td>-0.344767</td>\n",
       "      <td>0.054004</td>\n",
       "      <td>-0.196260</td>\n",
       "      <td>-0.264810</td>\n",
       "      <td>0.047066</td>\n",
       "      <td>0.070799</td>\n",
       "      <td>0.332548</td>\n",
       "      <td>-0.427511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.192925 -0.227320  0.531938  0.547458 -0.029546 -0.112131  0.177535   \n",
       "1    -0.105737 -0.160767  0.398062  0.659159 -0.267791 -0.235236  0.306701   \n",
       "2    -0.035192 -0.152306  0.482523  0.457505 -0.015983 -0.144561  0.206993   \n",
       "3    -0.177934 -0.083295  0.252004  0.577131 -0.376043 -0.251949  0.409394   \n",
       "4    -0.160648 -0.184098  0.346441  0.410458 -0.224065 -0.253801  0.338415   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995 -0.063082 -0.126341  0.437498  0.675349 -0.300340 -0.314575  0.332507   \n",
       "9996 -0.083859 -0.111094  0.420981  0.631187 -0.279325 -0.222907  0.283491   \n",
       "9997 -0.125323 -0.205932  0.365661  0.434190 -0.104743 -0.125283  0.429559   \n",
       "9998 -0.110458 -0.105682  0.404172  0.537259 -0.262631 -0.320473  0.374739   \n",
       "9999 -0.023008 -0.196995  0.479772  0.603899 -0.260130 -0.093538  0.142174   \n",
       "\n",
       "             7         8         9        10        11        12        13  \\\n",
       "0    -0.155894 -0.665188 -0.311368  0.471397 -0.581751 -0.310495  0.047058   \n",
       "1    -0.476188 -0.857286 -0.217737  0.459439 -0.639661 -0.425403  0.047152   \n",
       "2    -0.505070 -0.737938 -0.413103  0.552791 -0.428667 -0.335365  0.081298   \n",
       "3    -0.171015 -0.630986 -0.157952  0.465188 -0.520418 -0.268709 -0.060737   \n",
       "4    -0.520747 -0.698456 -0.148005  0.401808 -0.487821 -0.459717  0.068937   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995 -0.538570 -0.920960 -0.224309  0.603431 -0.625257 -0.436727  0.074245   \n",
       "9996 -0.420281 -0.893414 -0.182745  0.518702 -0.514142 -0.476802  0.043555   \n",
       "9997 -0.431185 -0.609905 -0.132508  0.499256 -0.596574 -0.356582 -0.122496   \n",
       "9998 -0.496816 -0.904411 -0.249470  0.433276 -0.496582 -0.509667  0.079502   \n",
       "9999 -0.301749 -0.832235 -0.303246  0.497656 -0.399801 -0.344767  0.054004   \n",
       "\n",
       "            14        15        16        17        18        19  \n",
       "0    -0.352483 -0.348064 -0.194387  0.024943  0.149389 -0.378988  \n",
       "1    -0.127996 -0.273561  0.023231 -0.089354  0.513522 -0.313904  \n",
       "2    -0.249936 -0.276294  0.036955 -0.213982  0.603942 -0.422719  \n",
       "3    -0.092826 -0.208967  0.056133  0.004946  0.443746 -0.446448  \n",
       "4    -0.204519 -0.150342  0.097417 -0.137441  0.448936 -0.506880  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "9995 -0.158525 -0.282326  0.140544 -0.080999  0.492803 -0.425586  \n",
       "9996 -0.162426 -0.252175  0.056786 -0.050622  0.423405 -0.484523  \n",
       "9997  0.102354  0.002644  0.267052  0.113557  0.425755 -0.410532  \n",
       "9998 -0.078198 -0.354974  0.131434  0.049244  0.507311 -0.418555  \n",
       "9999 -0.196260 -0.264810  0.047066  0.070799  0.332548 -0.427511  \n",
       "\n",
       "[10000 rows x 20 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_word_vectors_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bouhmid\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "linear_reg = LogisticRegression()\n",
    "linear_reg = linear_reg.fit(X_train, Y_train.to_numpy())\n",
    "y_pred = linear_reg.predict(avg_word_vectors_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def create_csv_submission(ids, y_pred, name):\n",
    "    \"\"\"\n",
    "    Creates an output file in csv format for submission to kaggle\n",
    "    Arguments: ids (event ids associated with each prediction)\n",
    "               y_pred (predicted class labels)\n",
    "               name (string name of .csv output file to be created)\n",
    "    \"\"\"\n",
    "    with open(name, 'w',newline='') as csvfile:\n",
    "        fieldnames = ['Id', 'Prediction']\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "            writer.writerow({'Id':int(r1),'Prediction':int(r2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [-1 if x==0 else 1 for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids=np.arange(1,10001)\n",
    "create_csv_submission(ids, y_pred, \"csv_submission_logistic_reg.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tweets = list(open(\"../cleaned_data/cleaned_train_pos.txt\", \"r\", encoding='utf-8').readlines())\n",
    "pos_tweets = [s.strip() for s in pos_tweets]\n",
    "neg_tweets = list(open(\"../cleaned_data/cleaned_train_neg.txt\", \"r\", encoding='utf-8').readlines())\n",
    "neg_tweets = [s.strip() for s in neg_tweets]\n",
    "test = list(open(\"../cleaned_data/cleaned_test_data.txt\", \"r\", encoding='utf-8').readlines())\n",
    "test = [s.strip() for s in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tweets = [line.split(',') for line in pos_tweets]\n",
    "neg_tweets = [line.split(',') for line in neg_tweets]\n",
    "test_tweets =[line.split(',') for line in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tweets = [ list(dict.fromkeys(tweet)) for tweet in pos_tweets]\n",
    "neg_tweets = [ list(dict.fromkeys(tweet)) for tweet in neg_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_pos_tweets = [word for tweet in pos_tweets for word in tweet]\n",
    "word_list_neg_tweets = [word for tweet in neg_tweets for word in tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_pos=0.5\n",
    "proba_neg=0.5\n",
    "log_prior_pos = np.log(proba_pos)\n",
    "log_prior_neg = np.log(proba_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_pos_tweets = [word for word in word_list_pos_tweets if word!='']\n",
    "word_list_neg_tweets = [word for word in word_list_neg_tweets if word!='']\n",
    "all_words = word_list_pos_tweets + word_list_neg_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary_count(all_words, pos_neg_words):\n",
    "    somme = 0\n",
    "    for word in all_words:\n",
    "        somme=somme+1+pos_neg_words.count(word)\n",
    "    return somme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_set = set(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "pos_dict = dict(Counter(word_list_pos_tweets))\n",
    "neg_dict = dict(Counter(word_list_neg_tweets))\n",
    "all_word_dict = dict(Counter(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_somme_pos(vocabulary_set,pos_dict):\n",
    "    somme = len(vocabulary_set)\n",
    "    for word in vocabulary_set:\n",
    "        if word in pos_dict.keys(): somme+=pos_dict.get(word)\n",
    "    return somme\n",
    "        \n",
    "def compute_somme_neg(vocabulary_set,neg_dict):\n",
    "    somme = len(vocabulary_set)\n",
    "    for word in vocabulary_set:\n",
    "        if word in neg_dict.keys(): somme+=neg_dict.get(word)\n",
    "    return somme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1316816\n",
      "1451065\n"
     ]
    }
   ],
   "source": [
    "pos_somme = compute_somme_pos(vocabulary_set,pos_dict)\n",
    "print(pos_somme)\n",
    "neg_somme = compute_somme_neg(vocabulary_set,neg_dict)\n",
    "print(neg_somme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood_pos(somme,vocabulary,pos_dict):\n",
    "    array = []\n",
    "    for word in vocabulary:\n",
    "        if word in pos_dict.keys():\n",
    "            likelihood = (pos_dict.get(word) + 1 ) / somme\n",
    "        else: likelihood= 1/somme\n",
    "        array.append(np.log(likelihood))\n",
    "    return array\n",
    "\n",
    "def loglikelihood_neg(somme,vocabulary,neg_dict):\n",
    "    array = []\n",
    "    for word in vocabulary:\n",
    "        if word in neg_dict.keys():\n",
    "            likelihood = (neg_dict.get(word) + 1 ) / somme\n",
    "        else: likelihood= 1/somme\n",
    "        array.append(np.log(likelihood))\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglikelihood_pos_values = loglikelihood_pos(pos_somme,vocabulary_set,pos_dict)\n",
    "loglikelihood_neg_values = loglikelihood_neg(pos_somme,vocabulary_set,neg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_likelihood_dict = dict(zip(list(vocabulary_set), loglikelihood_pos_values))\n",
    "neg_likelihood_dict = dict(zip(list(vocabulary_set), loglikelihood_neg_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets =[list(dict.fromkeys(tweet)) for tweet in test_tweets]\n",
    "test_tweets= [[word for word in tweet if word !='' and word in vocabulary_set] for tweet in test_tweets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_naive_bayes(test,loglikelihood_pos,loglikelihood_neg):\n",
    "    predictions = []\n",
    "    for tweet in test:\n",
    "        sum_pos = log_prior_pos\n",
    "        sum_neg = log_prior_neg\n",
    "        for word in tweet:\n",
    "            sum_pos=sum_pos+loglikelihood_pos.get(word)\n",
    "            sum_neg=sum_neg+loglikelihood_neg.get(word)\n",
    "        if sum_pos>sum_neg :\n",
    "            predictions.append(1)\n",
    "        else: predictions.append(-1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = function_naive_bayes(test_tweets,pos_likelihood_dict,neg_likelihood_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import create_csv_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(y_pred,\"../submissions/naive_bayes_clean_fourth_attempt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**this gave us 0.75 accuracy and 0.758 F1 score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9N4TUkP-wv9c"
   },
   "source": [
    "#### Working on sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69348,
     "status": "ok",
     "timestamp": 1607634041952,
     "user": {
      "displayName": "Ghribi nour",
      "photoUrl": "https://lh3.googleusercontent.com/-sF0zhzcPhXY/AAAAAAAAAAI/AAAAAAAAUw8/ANSSoVZye6o/s64/photo.jpg",
      "userId": "10556054115865158287"
     },
     "user_tz": -60
    },
    "id": "GPvjCzDZO0lP",
    "outputId": "330bd162-e052-4f38-ccd2-31e37b1a9005"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ommiting repetitions\n",
      "Translating emojis\n",
      "removing numbers\n",
      "adding <tag> for hashtags\n",
      "tokenizing\n",
      "removing pontuations\n",
      "dealing with slang words\n"
     ]
    }
   ],
   "source": [
    "pos_tweets, neg_tweets, test = load_cleaned_data(full=False, stop_words=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KXAVetlWeVel"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = create_train_test_dfs(pos_tweets, neg_tweets, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vfm1ssOnToML"
   },
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    df['cleaned_tweets'] = [\" \".join(word) for word in df['tweets']]\n",
    "    df['cleaned_tweets'] = df['cleaned_tweets'].apply(translate_emoji)\n",
    "    df['cleaned_tweets'] = [\" \".join(text_processor.pre_process_doc(tweet)) for tweet in df['cleaned_tweets']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 38146,
     "status": "ok",
     "timestamp": 1607294280303,
     "user": {
      "displayName": "Ghribi nour",
      "photoUrl": "https://lh3.googleusercontent.com/-sF0zhzcPhXY/AAAAAAAAAAI/AAAAAAAAUw8/ANSSoVZye6o/s64/photo.jpg",
      "userId": "10556054115865158287"
     },
     "user_tz": -60
    },
    "id": "WFRT_VWDRvX9",
    "outputId": "1128750e-f75a-4349-9209-c93333be5cd0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>sign</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[i, so, love, the, argentina, tvc, of, curt, s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i so love the argentina tvc of curt sol gorg h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[he, poked, him, in, the, eye]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>he poked him in the eye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[well, the, blackhawks, lost, tonight, well, i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>well the blackhawks lost tonight well i guess ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[i, do, not, need, tht, multistop, get, it, ba...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i do not need tht multistop get it back get it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[user, following, back]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>user following back</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  ...                                     cleaned_tweets\n",
       "0  [i, so, love, the, argentina, tvc, of, curt, s...  ...  i so love the argentina tvc of curt sol gorg h...\n",
       "1                     [he, poked, him, in, the, eye]  ...                            he poked him in the eye\n",
       "2  [well, the, blackhawks, lost, tonight, well, i...  ...  well the blackhawks lost tonight well i guess ...\n",
       "3  [i, do, not, need, tht, multistop, get, it, ba...  ...  i do not need tht multistop get it back get it...\n",
       "4                            [user, following, back]  ...                                user following back\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = clean_df(train_data)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBPKeIN1dpbR"
   },
   "outputs": [],
   "source": [
    "x = train_data['cleaned_tweets']\n",
    "y = train_data['sign']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.02, random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AKkcE3Ggd5xP"
   },
   "outputs": [],
   "source": [
    "checker_pipeline = Pipeline([('vectorizer',  TfidfVectorizer().set_params(\n",
    "        stop_words=None,\n",
    "        max_features=100000,\n",
    "        ngram_range=(1, 3))),\n",
    "                             ('classifier', Pipeline([('feature_selection',\n",
    "               SelectFromModel(LinearSVC(penalty=\"l1\", dual=False))),\n",
    "              ('classification', LinearSVC(penalty=\"l2\"))]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4MugkXw7fKJA"
   },
   "outputs": [],
   "source": [
    "def accuracy_summary(pipeline, x_train, y_train, x_test, y_test):\n",
    "\n",
    "    t0 = time()\n",
    "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(x_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"accuracy score: {0:.2f}%\".format(accuracy * 100))\n",
    "    print(\"train and test time: {0:.2f}s\".format(train_test_time))\n",
    "    print(\"-\" * 80)\n",
    "    return accuracy, train_test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37582,
     "status": "ok",
     "timestamp": 1607294317856,
     "user": {
      "displayName": "Ghribi nour",
      "photoUrl": "https://lh3.googleusercontent.com/-sF0zhzcPhXY/AAAAAAAAAAI/AAAAAAAAUw8/ANSSoVZye6o/s64/photo.jpg",
      "userId": "10556054115865158287"
     },
     "user_tz": -60
    },
    "id": "PynsthlJfaxK",
    "outputId": "25f8f65f-c9a9-4deb-9b05-cf4840d025e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 83.45%\n",
      "train and test time: 37.55s\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8345, 37.55270862579346)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_summary(\n",
    "        checker_pipeline, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O33dq1cugx5z"
   },
   "outputs": [],
   "source": [
    "x_train = train_data['cleaned_tweets']\n",
    "y_train = train_data['sign']\n",
    "\n",
    "test_data = clean_df(test_data)\n",
    "x_test = test_data['cleaned_tweets']\n",
    "\n",
    "sentiment_fit = checker_pipeline.fit(x_train,y_train)\n",
    "y_pred = sentiment_fit.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zXyBFunXiaHk"
   },
   "outputs": [],
   "source": [
    "y_pred = [-1 if pred == 0 else 1 for pred in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZXC1H85ikx3"
   },
   "outputs": [],
   "source": [
    "create_csv_submission(y_pred,\"SVM_trained_on_sample.csv\") #0.824 Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-jGumhzloTY"
   },
   "source": [
    "#### Working on full data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1096036,
     "status": "ok",
     "timestamp": 1607267769106,
     "user": {
      "displayName": "Ghribi nour",
      "photoUrl": "https://lh3.googleusercontent.com/-sF0zhzcPhXY/AAAAAAAAAAI/AAAAAAAAUw8/ANSSoVZye6o/s64/photo.jpg",
      "userId": "10556054115865158287"
     },
     "user_tz": -60
    },
    "id": "c4eNgDoHjt-y",
    "outputId": "0b8d7d7d-a220-4302-e021-4c10dcb7b877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ommiting repetitions\n",
      "Translating emojis\n",
      "removing numbers\n",
      "adding <tag> for hashtags\n",
      "tokenizing\n",
      "removing pontuations\n",
      "dealing with slang words\n"
     ]
    }
   ],
   "source": [
    "pos_tweets, neg_tweets, test = load_cleaned_data(full=True, stop_words=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AwvBAB26kAv5"
   },
   "outputs": [],
   "source": [
    "full_train_data, test_data = create_train_test_dfs(pos_tweets, neg_tweets, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OrFRfhBVkEEN"
   },
   "outputs": [],
   "source": [
    "full_train_data = clean_df(full_train_data)\n",
    "test_data = clean_df(test_data)\n",
    "\n",
    "x_train = full_train_data['cleaned_tweets']\n",
    "y_train = full_train_data['sign']\n",
    "\n",
    "x_test = test_data['cleaned_tweets']\n",
    "\n",
    "sentiment_fit = checker_pipeline.fit(x_train,y_train)\n",
    "y_pred = sentiment_fit.predict(x_test)\n",
    "y_pred = [-1 if pred == 0 else 1 for pred in y_pred]\n",
    "\n",
    "create_csv_submission(y_pred,\"SVM_trained_on_full_data.csv\") #0.849 Accuracy F-1 0.853"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
